"""LLM-based analyzer for unknown dataset types."""

import json
import os
from dataclasses import dataclass, field
from typing import Any, Optional


@dataclass
class LLMDatasetAnalysis:
    """Result of LLM analysis on dataset samples."""

    dataset_type: str = ""  # e.g., "instruction_tuning", "qa", "classification", etc.
    purpose: str = ""  # What is this dataset for?
    structure_description: str = ""  # Description of data structure
    key_fields: list = field(default_factory=list)  # Important fields and their roles
    production_steps: list = field(default_factory=list)  # How to produce similar data
    quality_criteria: list = field(default_factory=list)  # Quality standards
    annotation_guidelines: str = ""  # How to annotate/label data
    example_analysis: list = field(default_factory=list)  # Analysis of example items
    recommended_team: dict = field(default_factory=dict)  # Team composition
    estimated_difficulty: str = ""  # easy/medium/hard
    similar_datasets: list = field(default_factory=list)  # Known similar datasets
    raw_response: str = ""  # Raw LLM response for debugging


DATASET_ANALYSIS_PROMPT = '''ä½ æ˜¯ä¸€ä¸ªæ•°æ®é›†å·¥ç¨‹ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹æ•°æ®é›†æ ·æœ¬ï¼Œå¸®åŠ©ç”¨æˆ·ç†è§£å¦‚ä½•å¤åˆ»ç±»ä¼¼çš„æ•°æ®é›†ã€‚

## æ•°æ®é›†ä¿¡æ¯
- åç§°: {dataset_id}
- æ ·æœ¬æ•°: {sample_count}

## æ•°æ®ç»“æ„ (Schema)
```json
{schema}
```

## æ ·æœ¬æ•°æ® (å‰ {num_examples} æ¡)
```json
{examples}
```

## è¯·åˆ†æå¹¶è¾“å‡ºä»¥ä¸‹å†…å®¹ (JSON æ ¼å¼)

```json
{{
  "dataset_type": "æ•°æ®é›†ç±»å‹ï¼Œå¦‚: instruction_tuning, preference_ranking, qa, classification, code_generation, summarization, translation, dialogue, benchmark ç­‰",

  "purpose": "è¿™ä¸ªæ•°æ®é›†çš„ç”¨é€”æ˜¯ä»€ä¹ˆï¼Ÿç”¨ä¸€å¥è¯æè¿°",

  "structure_description": "æ•°æ®ç»“æ„çš„è¯¦ç»†æè¿°ï¼ŒåŒ…æ‹¬å„å­—æ®µçš„å«ä¹‰å’Œå…³ç³»",

  "key_fields": [
    {{"field": "å­—æ®µå", "role": "å­—æ®µä½œç”¨", "format": "æ•°æ®æ ¼å¼", "example_pattern": "å…¸å‹å†…å®¹æ¨¡å¼"}}
  ],

  "production_steps": [
    {{"step": 1, "name": "æ­¥éª¤åç§°", "description": "è¯¦ç»†è¯´æ˜", "who": "è°æ¥åš (äººå·¥/æœºå™¨/æ··åˆ)", "tools": ["å¯èƒ½ç”¨åˆ°çš„å·¥å…·"]}}
  ],

  "quality_criteria": [
    {{"criterion": "è´¨é‡æ ‡å‡†åç§°", "description": "å…·ä½“è¦æ±‚", "check_method": "å¦‚ä½•æ£€æŸ¥"}}
  ],

  "annotation_guidelines": "å¦‚æœéœ€è¦äººå·¥æ ‡æ³¨ï¼Œç»™å‡ºè¯¦ç»†çš„æ ‡æ³¨æŒ‡å—",

  "example_analysis": [
    {{"example_index": 0, "analysis": "å¯¹è¿™æ¡æ ·æœ¬çš„åˆ†æï¼ŒåŒ…æ‹¬å¥½çš„åœ°æ–¹å’Œå¯æ”¹è¿›çš„åœ°æ–¹"}}
  ],

  "recommended_team": {{
    "roles": [{{"role": "è§’è‰²åç§°", "count": "äººæ•°", "skills": ["æ‰€éœ€æŠ€èƒ½"]}}],
    "total_people": "æ€»äººæ•°èŒƒå›´"
  }},

  "estimated_difficulty": "easy/medium/hardï¼Œå¹¶è¯´æ˜åŸå› ",

  "similar_datasets": ["ç±»ä¼¼çš„çŸ¥åæ•°æ®é›†åç§°"]
}}
```

è¯·ç¡®ä¿è¾“å‡ºæœ‰æ•ˆçš„ JSON æ ¼å¼ã€‚åŸºäºæ ·æœ¬æ•°æ®ç»™å‡ºå…·ä½“ã€å¯æ“ä½œçš„å»ºè®®ã€‚'''


class LLMDatasetAnalyzer:
    """Analyze unknown dataset types using LLM."""

    def __init__(self, provider: str = "anthropic"):
        """Initialize analyzer.

        Args:
            provider: LLM provider ("anthropic" or "openai")
        """
        self.provider = provider
        self._client = None

    def _get_client(self):
        """Get or create LLM client."""
        if self._client is not None:
            return self._client

        if self.provider == "anthropic":
            try:
                import anthropic

                api_key = os.environ.get("ANTHROPIC_API_KEY")
                if not api_key:
                    raise ValueError("ANTHROPIC_API_KEY not set")
                self._client = anthropic.Anthropic(api_key=api_key)
            except ImportError:
                raise ImportError("Please install: pip install anthropic")
        elif self.provider == "openai":
            try:
                import openai

                api_key = os.environ.get("OPENAI_API_KEY")
                if not api_key:
                    raise ValueError("OPENAI_API_KEY not set")
                self._client = openai.OpenAI(api_key=api_key)
            except ImportError:
                raise ImportError("Please install: pip install openai")
        else:
            raise ValueError(f"Unknown provider: {self.provider}")

        return self._client

    def analyze(
        self,
        dataset_id: str,
        schema_info: dict,
        sample_items: list,
        sample_count: int,
    ) -> LLMDatasetAnalysis:
        """Analyze dataset samples using LLM.

        Args:
            dataset_id: Dataset identifier
            schema_info: Schema information dict
            sample_items: List of sample data items
            sample_count: Total number of samples analyzed

        Returns:
            LLMDatasetAnalysis with extracted insights
        """
        # Prepare schema for prompt
        schema_str = json.dumps(
            {k: {"type": v["type"], "nested": v.get("nested_type")} for k, v in schema_info.items()},
            indent=2,
            ensure_ascii=False,
        )

        # Prepare examples (truncate long values)
        def truncate_item(item: dict, max_len: int = 500) -> dict:
            result = {}
            for k, v in item.items():
                if isinstance(v, str) and len(v) > max_len:
                    result[k] = v[:max_len] + "..."
                elif isinstance(v, list) and len(v) > 5:
                    result[k] = v[:5] + ["..."]
                else:
                    result[k] = v
            return result

        examples = [truncate_item(item) for item in sample_items[:5]]
        examples_str = json.dumps(examples, indent=2, ensure_ascii=False)

        # Build prompt
        prompt = DATASET_ANALYSIS_PROMPT.format(
            dataset_id=dataset_id,
            sample_count=sample_count,
            schema=schema_str,
            examples=examples_str,
            num_examples=len(examples),
        )

        # Call LLM
        try:
            client = self._get_client()

            if self.provider == "anthropic":
                response = client.messages.create(
                    model="claude-sonnet-4-20250514",
                    max_tokens=4000,
                    messages=[{"role": "user", "content": prompt}],
                )
                response_text = response.content[0].text
            else:
                response = client.chat.completions.create(
                    model="gpt-4o",
                    max_tokens=4000,
                    messages=[{"role": "user", "content": prompt}],
                )
                response_text = response.choices[0].message.content

            # Parse JSON from response
            result = self._parse_response(response_text)
            result.raw_response = response_text
            return result

        except Exception as e:
            # Return empty result with error info
            return LLMDatasetAnalysis(
                dataset_type="unknown",
                purpose=f"LLM analysis failed: {e}",
                raw_response=str(e),
            )

    def _parse_response(self, response_text: str) -> LLMDatasetAnalysis:
        """Parse LLM response into structured result."""
        import re

        # Try to extract JSON block
        json_match = re.search(r"```json\s*(.*?)\s*```", response_text, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            # Try parsing entire response
            json_str = response_text

        try:
            data = json.loads(json_str)
            return LLMDatasetAnalysis(
                dataset_type=data.get("dataset_type", "unknown"),
                purpose=data.get("purpose", ""),
                structure_description=data.get("structure_description", ""),
                key_fields=data.get("key_fields", []),
                production_steps=data.get("production_steps", []),
                quality_criteria=data.get("quality_criteria", []),
                annotation_guidelines=data.get("annotation_guidelines", ""),
                example_analysis=data.get("example_analysis", []),
                recommended_team=data.get("recommended_team", {}),
                estimated_difficulty=data.get("estimated_difficulty", ""),
                similar_datasets=data.get("similar_datasets", []),
            )
        except json.JSONDecodeError:
            return LLMDatasetAnalysis(
                dataset_type="unknown",
                purpose="Failed to parse LLM response",
                raw_response=response_text,
            )


def generate_llm_guide_section(analysis: LLMDatasetAnalysis) -> str:
    """Generate reproduction guide section from LLM analysis.

    Args:
        analysis: LLM analysis result

    Returns:
        Markdown string for the guide
    """
    lines = []

    lines.append("## ğŸ¤– LLM æ™ºèƒ½åˆ†æç»“æœ")
    lines.append("")
    lines.append(f"> æ•°æ®é›†ç±»å‹: **{analysis.dataset_type}**")
    lines.append(f">")
    lines.append(f"> {analysis.purpose}")
    lines.append("")

    # Structure description
    if analysis.structure_description:
        lines.append("### æ•°æ®ç»“æ„è§£è¯»")
        lines.append("")
        lines.append(analysis.structure_description)
        lines.append("")

    # Key fields
    if analysis.key_fields:
        lines.append("### å…³é”®å­—æ®µè¯´æ˜")
        lines.append("")
        lines.append("| å­—æ®µ | ä½œç”¨ | æ ¼å¼ | å†…å®¹æ¨¡å¼ |")
        lines.append("|------|------|------|----------|")
        for f in analysis.key_fields:
            if isinstance(f, dict):
                lines.append(
                    f"| `{f.get('field', '')}` | {f.get('role', '')} | {f.get('format', '')} | {f.get('example_pattern', '')} |"
                )
        lines.append("")

    # Production steps
    if analysis.production_steps:
        lines.append("### ç”Ÿäº§æµç¨‹ (SOP)")
        lines.append("")
        lines.append("```")
        for step in analysis.production_steps:
            if isinstance(step, dict):
                step_num = step.get("step", "?")
                name = step.get("name", "")
                desc = step.get("description", "")
                who = step.get("who", "")
                tools = step.get("tools", [])
                lines.append(f"Step {step_num}: {name}")
                lines.append(f"  æè¿°: {desc}")
                lines.append(f"  æ‰§è¡Œè€…: {who}")
                if tools:
                    lines.append(f"  å·¥å…·: {', '.join(tools)}")
                lines.append("")
        lines.append("```")
        lines.append("")

    # Quality criteria
    if analysis.quality_criteria:
        lines.append("### è´¨é‡æ ‡å‡†")
        lines.append("")
        lines.append("| æ ‡å‡† | è¦æ±‚ | æ£€æŸ¥æ–¹æ³• |")
        lines.append("|------|------|----------|")
        for c in analysis.quality_criteria:
            if isinstance(c, dict):
                lines.append(
                    f"| {c.get('criterion', '')} | {c.get('description', '')} | {c.get('check_method', '')} |"
                )
        lines.append("")

    # Annotation guidelines
    if analysis.annotation_guidelines:
        lines.append("### æ ‡æ³¨æŒ‡å—")
        lines.append("")
        lines.append(analysis.annotation_guidelines)
        lines.append("")

    # Team recommendation
    if analysis.recommended_team and analysis.recommended_team.get("roles"):
        lines.append("### å›¢é˜Ÿé…ç½®å»ºè®®")
        lines.append("")
        lines.append("| è§’è‰² | äººæ•° | æ‰€éœ€æŠ€èƒ½ |")
        lines.append("|------|------|----------|")
        for role in analysis.recommended_team.get("roles", []):
            if isinstance(role, dict):
                skills = ", ".join(role.get("skills", []))
                lines.append(f"| {role.get('role', '')} | {role.get('count', '')} | {skills} |")
        total = analysis.recommended_team.get("total_people", "")
        if total:
            lines.append(f"\n**æ€»äººæ•°**: {total}")
        lines.append("")

    # Difficulty
    if analysis.estimated_difficulty:
        lines.append("### å¤åˆ»éš¾åº¦è¯„ä¼°")
        lines.append("")
        lines.append(f"**éš¾åº¦**: {analysis.estimated_difficulty}")
        lines.append("")

    # Similar datasets
    if analysis.similar_datasets:
        lines.append("### ç›¸ä¼¼æ•°æ®é›†å‚è€ƒ")
        lines.append("")
        for ds in analysis.similar_datasets:
            lines.append(f"- {ds}")
        lines.append("")

    lines.append("---")
    lines.append("")

    return "\n".join(lines)
