"""æœ¬åœ°æ–‡ä»¶ Providerâ€”â€”é»˜è®¤å®ç°

å°†æŠ•äº§é…ç½®è¾“å‡ºåˆ°æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿï¼Œç”Ÿæˆå®Œæ•´çš„é¡¹ç›®ç»“æ„ã€‚
"""

from pathlib import Path
from datetime import datetime
from typing import Optional
import yaml

from datarecipe.schema import (
    DataRecipe,
    ProductionConfig,
    AnnotatorProfile,
    ValidationResult,
    AnnotatorMatch,
    ProjectHandle,
    DeploymentResult,
    ProjectStatus,
)


class LocalFilesProvider:
    """æœ¬åœ°æ–‡ä»¶ Provider"""

    @property
    def name(self) -> str:
        return "local"

    @property
    def description(self) -> str:
        return "è¾“å‡ºåˆ°æœ¬åœ°æ–‡ä»¶ï¼ˆé»˜è®¤ providerï¼‰"

    def validate_config(self, config: ProductionConfig) -> ValidationResult:
        """éªŒè¯é…ç½®"""
        errors = []
        warnings = []

        if not config.annotation_guide:
            warnings.append("æ ‡æ³¨æŒ‡å—ä¸ºç©º")

        if not config.quality_rules:
            warnings.append("æœªå®šä¹‰è´¨æ£€è§„åˆ™")

        if not config.acceptance_criteria:
            warnings.append("æœªå®šä¹‰éªŒæ”¶æ ‡å‡†")

        return ValidationResult(
            valid=len(errors) == 0,
            errors=errors,
            warnings=warnings,
        )

    def match_annotators(
        self,
        profile: AnnotatorProfile,
        limit: int = 10,
    ) -> list[AnnotatorMatch]:
        """æœ¬åœ°æ¨¡å¼ä¸æ”¯æŒåŒ¹é…æ ‡æ³¨è€…"""
        return []

    def create_project(
        self,
        recipe: DataRecipe,
        config: Optional[ProductionConfig] = None,
        output_dir: str = "./project",
    ) -> ProjectHandle:
        """åˆ›å»ºæœ¬åœ°é¡¹ç›®ç»“æ„

        Args:
            recipe: æ•°æ®é…æ–¹
            config: æŠ•äº§é…ç½®
            output_dir: è¾“å‡ºç›®å½•

        Returns:
            ProjectHandle é¡¹ç›®å¥æŸ„
        """
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        files_created = []

        # 1. recipe.yaml
        recipe_path = output_path / "recipe.yaml"
        recipe_path.write_text(
            yaml.dump(recipe.to_dict(), default_flow_style=False, allow_unicode=True),
            encoding="utf-8"
        )
        files_created.append(str(recipe_path))

        # 2. annotator_profile.yaml
        if recipe.annotator_profile:
            profile_path = output_path / "annotator_profile.yaml"
            profile_path.write_text(recipe.annotator_profile.to_yaml(), encoding="utf-8")
            files_created.append(str(profile_path))

        # 3. cost_estimate.yaml
        if recipe.enhanced_cost:
            cost_path = output_path / "cost_estimate.yaml"
            cost_path.write_text(
                yaml.dump(recipe.enhanced_cost.to_dict(), default_flow_style=False, allow_unicode=True),
                encoding="utf-8"
            )
            files_created.append(str(cost_path))

        # 4. annotation_guide.md
        if config and config.annotation_guide:
            guide_path = output_path / "annotation_guide.md"
            guide_path.write_text(config.annotation_guide, encoding="utf-8")
            files_created.append(str(guide_path))

        # 5. quality_rules.yaml + quality_rules.md (äººç±»å¯è¯»ç‰ˆæœ¬)
        if config and config.quality_rules:
            rules_path = output_path / "quality_rules.yaml"
            rules_data = [r.to_dict() for r in config.quality_rules]
            rules_path.write_text(
                yaml.dump(rules_data, default_flow_style=False, allow_unicode=True),
                encoding="utf-8"
            )
            files_created.append(str(rules_path))

            # ç”Ÿæˆäººç±»å¯è¯»çš„ Markdown ç‰ˆæœ¬
            rules_md_path = output_path / "quality_rules.md"
            rules_md_content = self._generate_quality_rules_md(config.quality_rules)
            rules_md_path.write_text(rules_md_content, encoding="utf-8")
            files_created.append(str(rules_md_path))

        # 6. acceptance_criteria.yaml + acceptance_criteria.md (äººç±»å¯è¯»ç‰ˆæœ¬)
        if config and config.acceptance_criteria:
            criteria_path = output_path / "acceptance_criteria.yaml"
            criteria_data = [c.to_dict() for c in config.acceptance_criteria]
            criteria_path.write_text(
                yaml.dump(criteria_data, default_flow_style=False, allow_unicode=True),
                encoding="utf-8"
            )
            files_created.append(str(criteria_path))

            # ç”Ÿæˆäººç±»å¯è¯»çš„ Markdown ç‰ˆæœ¬
            criteria_md_path = output_path / "acceptance_criteria.md"
            criteria_md_content = self._generate_acceptance_criteria_md(config.acceptance_criteria)
            criteria_md_path.write_text(criteria_md_content, encoding="utf-8")
            files_created.append(str(criteria_md_path))

        # 7. timeline.md
        if config and config.milestones:
            timeline_path = output_path / "timeline.md"
            timeline_content = self._generate_timeline_md(config)
            timeline_path.write_text(timeline_content, encoding="utf-8")
            files_created.append(str(timeline_path))

        # 8. README.md
        readme_path = output_path / "README.md"
        readme_content = self._generate_readme(recipe, config)
        readme_path.write_text(readme_content, encoding="utf-8")
        files_created.append(str(readme_path))

        # 9. scripts/ ç›®å½•
        scripts_dir = output_path / "scripts"
        scripts_dir.mkdir(exist_ok=True)

        # ç”Ÿæˆè„šæœ¬æ–‡ä»¶
        script_files = self._generate_scripts(recipe, scripts_dir)
        files_created.extend(script_files)

        return ProjectHandle(
            project_id=f"local_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            provider="local",
            created_at=datetime.now().isoformat(),
            status="created",
            metadata={
                "output_dir": str(output_path),
                "files_created": files_created,
            },
        )

    def submit(self, project: ProjectHandle) -> DeploymentResult:
        """æœ¬åœ°æ¨¡å¼ä¸éœ€è¦æäº¤"""
        return DeploymentResult(
            success=True,
            project_handle=project,
            details={"message": "æœ¬åœ°é¡¹ç›®åˆ›å»ºæˆåŠŸ"},
        )

    def get_status(self, project: ProjectHandle) -> ProjectStatus:
        """è·å–é¡¹ç›®çŠ¶æ€"""
        return ProjectStatus(
            status="completed",
            progress=100.0,
            completed_count=0,
            total_count=0,
        )

    def cancel(self, project: ProjectHandle) -> bool:
        """å–æ¶ˆé¡¹ç›®"""
        return True

    def _generate_readme(self, recipe: DataRecipe, config: Optional[ProductionConfig]) -> str:
        """ç”Ÿæˆ README"""
        lines = []
        lines.append(f"# {recipe.name} æŠ•äº§é¡¹ç›®")
        lines.append("")
        lines.append("## é¡¹ç›®æ¦‚è¿°")
        lines.append("")
        if recipe.description:
            lines.append(recipe.description)
        lines.append("")

        # åŸºæœ¬ä¿¡æ¯
        lines.append("## åŸºæœ¬ä¿¡æ¯")
        lines.append("")
        lines.append("| å±æ€§ | å€¼ |")
        lines.append("|------|-----|")
        lines.append(f"| **æ•°æ®é›†åç§°** | {recipe.name} |")
        lines.append(f"| **æ•°æ®æ¥æº** | {recipe.source_type.value} |")
        if recipe.num_examples:
            lines.append(f"| **ç›®æ ‡æ•°é‡** | {recipe.num_examples:,} |")
        if recipe.synthetic_ratio is not None:
            lines.append(f"| **åˆæˆæ¯”ä¾‹** | {recipe.synthetic_ratio * 100:.0f}% |")
        if recipe.teacher_models:
            lines.append(f"| **æ•™å¸ˆæ¨¡å‹** | {', '.join(recipe.teacher_models)} |")
        lines.append("")

        # æˆæœ¬ä¼°ç®—
        if recipe.enhanced_cost:
            lines.append("## æˆæœ¬ä¼°ç®—")
            lines.append("")
            lines.append(f"- **API æˆæœ¬**: ${recipe.enhanced_cost.api_cost:,.2f}")
            lines.append(f"- **äººåŠ›æˆæœ¬**: ${recipe.enhanced_cost.human_cost:,.2f}")
            lines.append(f"- **æ€»æˆæœ¬**: ${recipe.enhanced_cost.total_cost:,.2f}")
            lines.append(f"- **æˆæœ¬åŒºé—´**: ${recipe.enhanced_cost.total_range['low']:,.2f} - ${recipe.enhanced_cost.total_range['high']:,.2f}")
            lines.append("")

        # é¡¹ç›®ç»“æ„
        lines.append("## é¡¹ç›®ç»“æ„")
        lines.append("")
        lines.append("```")
        lines.append("./")
        lines.append("â”œâ”€â”€ README.md              # æœ¬æ–‡ä»¶")
        lines.append("â”œâ”€â”€ recipe.yaml            # æ•°æ®é…æ–¹")
        lines.append("â”œâ”€â”€ annotator_profile.yaml # æ ‡æ³¨ä¸“å®¶ç”»åƒ")
        lines.append("â”œâ”€â”€ cost_estimate.yaml     # æˆæœ¬ä¼°ç®—")
        lines.append("â”œâ”€â”€ annotation_guide.md    # æ ‡æ³¨æŒ‡å—")
        lines.append("â”œâ”€â”€ quality_rules.yaml     # è´¨æ£€è§„åˆ™")
        lines.append("â”œâ”€â”€ acceptance_criteria.yaml # éªŒæ”¶æ ‡å‡†")
        lines.append("â”œâ”€â”€ timeline.md            # é¡¹ç›®æ—¶é—´çº¿")
        lines.append("â””â”€â”€ scripts/               # è„šæœ¬ç›®å½•")
        lines.append("    â”œâ”€â”€ 01_prepare_data.py")
        lines.append("    â”œâ”€â”€ 02_generate.py")
        lines.append("    â””â”€â”€ 03_validate.py")
        lines.append("```")
        lines.append("")

        # å¿«é€Ÿå¼€å§‹
        lines.append("## å¿«é€Ÿå¼€å§‹")
        lines.append("")
        lines.append("1. é˜…è¯» `annotation_guide.md` äº†è§£æ ‡æ³¨è¦æ±‚")
        lines.append("2. æ ¹æ® `annotator_profile.yaml` ç»„å»ºå›¢é˜Ÿ")
        lines.append("3. æŒ‰ç…§ `timeline.md` æ‰§è¡Œé¡¹ç›®")
        lines.append("4. ä½¿ç”¨ `quality_rules.yaml` è¿›è¡Œè´¨æ£€")
        lines.append("")

        # æ—¶é—´è§„åˆ’
        if config and config.milestones:
            lines.append("## é‡Œç¨‹ç¢‘")
            lines.append("")
            for i, m in enumerate(config.milestones, 1):
                lines.append(f"{i}. **{m.name}** ({m.estimated_days} å¤©)")
                for d in m.deliverables:
                    lines.append(f"   - {d}")
            lines.append("")

        lines.append("---")
        lines.append("*ç”± DataRecipe ç”Ÿæˆ*")
        return "\n".join(lines)

    def _generate_timeline_md(self, config: ProductionConfig) -> str:
        """ç”Ÿæˆæ—¶é—´çº¿æ–‡æ¡£"""
        lines = []
        lines.append("# é¡¹ç›®æ—¶é—´çº¿")
        lines.append("")
        lines.append(f"**é¢„è®¡æ€»å·¥æœŸ**: {config.estimated_timeline_days} å¤©")
        lines.append("")
        lines.append(f"**å®¡æ ¸æµç¨‹**: {config.review_workflow.value}")
        lines.append(f"**æŠ½æ£€æ¯”ä¾‹**: {config.review_sample_rate * 100:.0f}%")
        lines.append("")

        lines.append("## é‡Œç¨‹ç¢‘")
        lines.append("")

        total_days = 0
        for i, m in enumerate(config.milestones, 1):
            lines.append(f"### M{i}: {m.name}")
            lines.append("")
            lines.append(f"**æè¿°**: {m.description}")
            lines.append(f"**é¢„è®¡å¤©æ•°**: {m.estimated_days}")
            lines.append(f"**ç´¯è®¡å¤©æ•°**: {total_days + m.estimated_days}")
            total_days += m.estimated_days
            lines.append("")
            if m.dependencies:
                lines.append(f"**ä¾èµ–**: {', '.join(m.dependencies)}")
                lines.append("")
            lines.append("**äº¤ä»˜ç‰©**:")
            for d in m.deliverables:
                lines.append(f"- [ ] {d}")
            lines.append("")

        lines.append("## ç”˜ç‰¹å›¾")
        lines.append("")
        lines.append("```")
        current = 0
        for m in config.milestones:
            bar = " " * current + "=" * m.estimated_days
            lines.append(f"{m.name[:15]:<15} |{bar}")
            current += m.estimated_days
        lines.append(f"{'æ€»è®¡':<15} |{'=' * current}")
        lines.append("```")

        return "\n".join(lines)

    def _generate_quality_rules_md(self, rules: list) -> str:
        """ç”Ÿæˆäººç±»å¯è¯»çš„è´¨æ£€è§„åˆ™æ–‡æ¡£"""
        lines = []
        lines.append("# è´¨æ£€è§„åˆ™è¯´æ˜")
        lines.append("")
        lines.append("æœ¬æ–‡æ¡£å®šä¹‰äº†æ•°æ®æ ‡æ³¨çš„è´¨é‡æ£€æŸ¥è§„åˆ™ï¼Œç¡®ä¿äº¤ä»˜æ•°æ®ç¬¦åˆè´¨é‡æ ‡å‡†ã€‚")
        lines.append("")

        # è§„åˆ™ä¸¥é‡ç¨‹åº¦è¯´æ˜
        lines.append("## ä¸¥é‡ç¨‹åº¦è¯´æ˜")
        lines.append("")
        lines.append("| çº§åˆ« | å›¾æ ‡ | å«ä¹‰ | å¤„ç†æ–¹å¼ |")
        lines.append("|------|------|------|----------|")
        lines.append("| **error** | ğŸ”´ | ä¸¥é‡é—®é¢˜ | å¿…é¡»ä¿®å¤åæ‰èƒ½é€šè¿‡ |")
        lines.append("| **warning** | ğŸŸ¡ | æ½œåœ¨é—®é¢˜ | å»ºè®®ä¿®å¤ï¼Œå¯é…Œæƒ…æ”¾è¿‡ |")
        lines.append("| **info** | ğŸ”µ | æç¤ºä¿¡æ¯ | ä»…ä¾›å‚è€ƒ |")
        lines.append("")

        # æ£€æŸ¥ç±»å‹è¯´æ˜
        lines.append("## æ£€æŸ¥ç±»å‹è¯´æ˜")
        lines.append("")
        lines.append("| ç±»å‹ | å«ä¹‰ | ç¤ºä¾‹ |")
        lines.append("|------|------|------|")
        lines.append("| **format** | æ ¼å¼æ£€æŸ¥ | å­—æ®µæ˜¯å¦ä¸ºç©ºã€é•¿åº¦æ˜¯å¦åˆè§„ã€JSON æ ¼å¼æ˜¯å¦æ­£ç¡® |")
        lines.append("| **content** | å†…å®¹æ£€æŸ¥ | äº‹å®æ˜¯å¦å‡†ç¡®ã€æ˜¯å¦æœ‰ AI ç—•è¿¹ã€æ˜¯å¦ç¬¦åˆä¸»é¢˜ |")
        lines.append("| **consistency** | ä¸€è‡´æ€§æ£€æŸ¥ | æ˜¯å¦ä¸å…¶ä»–æ•°æ®é‡å¤ã€é£æ ¼æ˜¯å¦ç»Ÿä¸€ |")
        lines.append("")

        # è§„åˆ™è¯¦æƒ…
        lines.append("## è§„åˆ™è¯¦æƒ…")
        lines.append("")

        # æŒ‰ç±»å‹åˆ†ç»„
        rules_by_type = {}
        for r in rules:
            check_type = r.check_type if hasattr(r, 'check_type') else r.get('type', 'other')
            if check_type not in rules_by_type:
                rules_by_type[check_type] = []
            rules_by_type[check_type].append(r)

        type_names = {
            'format': 'ğŸ“‹ æ ¼å¼æ£€æŸ¥è§„åˆ™',
            'content': 'ğŸ“ å†…å®¹æ£€æŸ¥è§„åˆ™',
            'consistency': 'ğŸ”— ä¸€è‡´æ€§æ£€æŸ¥è§„åˆ™',
        }

        for check_type, type_rules in rules_by_type.items():
            lines.append(f"### {type_names.get(check_type, check_type)}")
            lines.append("")

            for r in type_rules:
                rule_id = r.rule_id if hasattr(r, 'rule_id') else r.get('id', '')
                name = r.name if hasattr(r, 'name') else r.get('name', '')
                desc = r.description if hasattr(r, 'description') else r.get('description', '')
                severity = r.severity if hasattr(r, 'severity') else r.get('severity', 'warning')
                auto = r.auto_check if hasattr(r, 'auto_check') else r.get('auto_check', False)

                # ä¸¥é‡ç¨‹åº¦å›¾æ ‡
                severity_icon = {'error': 'ğŸ”´', 'warning': 'ğŸŸ¡', 'info': 'ğŸ”µ'}.get(severity, 'âšª')
                auto_label = "âœ… è‡ªåŠ¨æ£€æŸ¥" if auto else "ğŸ‘¤ äººå·¥æ£€æŸ¥"

                lines.append(f"#### {severity_icon} {rule_id}: {name}")
                lines.append("")
                lines.append(f"**æè¿°**: {desc}")
                lines.append("")
                lines.append(f"- **ä¸¥é‡ç¨‹åº¦**: {severity}")
                lines.append(f"- **æ£€æŸ¥æ–¹å¼**: {auto_label}")
                lines.append("")

        # ä½¿ç”¨æŒ‡å—
        lines.append("## ä½¿ç”¨æŒ‡å—")
        lines.append("")
        lines.append("### è´¨æ£€æµç¨‹")
        lines.append("")
        lines.append("1. **è‡ªåŠ¨æ£€æŸ¥**: ç³»ç»Ÿè‡ªåŠ¨æ‰§è¡Œæ ‡è®°ä¸ºã€Œè‡ªåŠ¨æ£€æŸ¥ã€çš„è§„åˆ™")
        lines.append("2. **äººå·¥æŠ½æ£€**: è´¨æ£€å‘˜éšæœºæŠ½å–æ ·æœ¬è¿›è¡Œäººå·¥æ£€æŸ¥")
        lines.append("3. **é—®é¢˜æ ‡è®°**: å‘ç°é—®é¢˜çš„æ•°æ®æ ‡è®°å¯¹åº”è§„åˆ™ ID")
        lines.append("4. **ä¿®æ­£åé¦ˆ**: æ ‡æ³¨å‘˜æ ¹æ®é—®é¢˜åé¦ˆè¿›è¡Œä¿®æ­£")
        lines.append("5. **å¤æ ¸éªŒæ”¶**: ä¿®æ­£åé‡æ–°æ£€æŸ¥ç›´è‡³é€šè¿‡")
        lines.append("")

        lines.append("### å¸¸è§é—®é¢˜")
        lines.append("")
        lines.append("**Q: åŒæ—¶è§¦å‘å¤šæ¡è§„åˆ™æ€ä¹ˆåŠï¼Ÿ**")
        lines.append("A: ä¼˜å…ˆå¤„ç† error çº§åˆ«çš„é—®é¢˜ï¼Œwarning å¯åœ¨åç»­æ‰¹é‡å¤„ç†ã€‚")
        lines.append("")
        lines.append("**Q: è§„åˆ™åˆ¤æ–­æœ‰æ­§ä¹‰æ€ä¹ˆåŠï¼Ÿ**")
        lines.append("A: è”ç³»é¡¹ç›®è´Ÿè´£äººç¡®è®¤ï¼Œå¿…è¦æ—¶æ›´æ–°è§„åˆ™è¯´æ˜ã€‚")
        lines.append("")

        lines.append("---")
        lines.append("*ç”± DataRecipe ç”Ÿæˆ*")

        return "\n".join(lines)

    def _generate_acceptance_criteria_md(self, criteria: list) -> str:
        """ç”Ÿæˆäººç±»å¯è¯»çš„éªŒæ”¶æ ‡å‡†æ–‡æ¡£"""
        lines = []
        lines.append("# éªŒæ”¶æ ‡å‡†è¯´æ˜")
        lines.append("")
        lines.append("æœ¬æ–‡æ¡£å®šä¹‰äº†é¡¹ç›®éªŒæ”¶çš„é‡åŒ–æ ‡å‡†ï¼Œæ‰€æœ‰æŒ‡æ ‡è¾¾æ ‡åæ–¹å¯æ­£å¼äº¤ä»˜ã€‚")
        lines.append("")

        # æ€»è§ˆè¡¨
        lines.append("## éªŒæ”¶æŒ‡æ ‡æ€»è§ˆ")
        lines.append("")
        lines.append("| æŒ‡æ ‡ | é˜ˆå€¼ | ä¼˜å…ˆçº§ | è¯´æ˜ |")
        lines.append("|------|------|--------|------|")

        for c in criteria:
            name = c.name if hasattr(c, 'name') else c.get('name', '')
            threshold = c.threshold if hasattr(c, 'threshold') else c.get('threshold', 0)
            priority = c.priority if hasattr(c, 'priority') else c.get('priority', 'required')
            desc = c.description if hasattr(c, 'description') else c.get('description', '')

            # ä¼˜å…ˆçº§å›¾æ ‡
            priority_icon = "ğŸ”´ å¿…é¡»" if priority == 'required' else "ğŸŸ¢ å»ºè®®"
            threshold_str = f"{threshold * 100:.0f}%" if threshold <= 1 else str(threshold)

            lines.append(f"| **{name}** | â‰¥ {threshold_str} | {priority_icon} | {desc} |")

        lines.append("")

        # è¯¦ç»†è¯´æ˜
        lines.append("## æŒ‡æ ‡è¯¦ç»†è¯´æ˜")
        lines.append("")

        metric_explanations = {
            'completeness': {
                'title': 'ğŸ“Š å®Œæˆç‡',
                'what': 'è¡¡é‡æ ‡æ³¨ä»»åŠ¡çš„å®Œæˆç¨‹åº¦',
                'how': 'å®Œæˆç‡ = å·²å®Œæˆæ¡æ•° / æ€»ä»»åŠ¡æ¡æ•° Ã— 100%',
                'tips': [
                    'ç¡®ä¿æ‰€æœ‰åˆ†é…çš„ä»»åŠ¡éƒ½å·²å¤„ç†',
                    'ã€Œæ— æ³•æ ‡æ³¨ã€çš„æ•°æ®ä¹Ÿè®¡å…¥å·²å®Œæˆ',
                    'æ¯æ—¥åŒæ­¥è¿›åº¦ï¼ŒåŠæ—¶å‘ç°è½åæƒ…å†µ',
                ],
            },
            'accuracy': {
                'title': 'ğŸ¯ å‡†ç¡®ç‡',
                'what': 'è¡¡é‡æ ‡æ³¨ç»“æœçš„æ­£ç¡®ç¨‹åº¦',
                'how': 'å‡†ç¡®ç‡ = æŠ½æ£€æ­£ç¡®æ•° / æŠ½æ£€æ€»æ•° Ã— 100%',
                'tips': [
                    'ç”±è´¨æ£€å‘˜éšæœºæŠ½æ ·æ£€æŸ¥',
                    'ä¸æ ‡å‡†ç­”æ¡ˆæˆ–ä¸“å®¶åˆ¤æ–­å¯¹æ¯”',
                    'ä½äºé˜ˆå€¼éœ€è¦è¿”å·¥ä¿®æ­£',
                ],
            },
            'agreement': {
                'title': 'ğŸ¤ ä¸€è‡´æ€§',
                'what': 'è¡¡é‡ä¸åŒæ ‡æ³¨è€…ä¹‹é—´çš„æ ‡æ³¨ä¸€è‡´ç¨‹åº¦',
                'how': 'ä½¿ç”¨ Cohen\'s Kappa ç³»æ•°è¡¡é‡ï¼Œå€¼åŸŸ [-1, 1]',
                'tips': [
                    'Kappa â‰¥ 0.8: å‡ ä¹å®Œå…¨ä¸€è‡´ï¼ˆä¼˜ç§€ï¼‰',
                    'Kappa â‰¥ 0.6: åŸºæœ¬ä¸€è‡´ï¼ˆè‰¯å¥½ï¼‰',
                    'Kappa < 0.4: ä¸€è‡´æ€§å·®ï¼ˆéœ€æ”¹è¿›ï¼‰',
                ],
            },
            'format': {
                'title': 'ğŸ“‹ æ ¼å¼åˆè§„',
                'what': 'è¡¡é‡æ•°æ®æ ¼å¼çš„è§„èŒƒç¨‹åº¦',
                'how': 'æ ¼å¼åˆè§„ç‡ = æ ¼å¼æ­£ç¡®æ¡æ•° / æ€»æ¡æ•° Ã— 100%',
                'tips': [
                    'ä½¿ç”¨è‡ªåŠ¨åŒ–è„šæœ¬æ£€æŸ¥',
                    'JSON æ ¼å¼ã€å­—æ®µå®Œæ•´æ€§ã€ç¼–ç è§„èŒƒ',
                    'æ ¼å¼é”™è¯¯å¿…é¡» 100% ä¿®å¤',
                ],
            },
            'timeliness': {
                'title': 'â° æ—¶æ•ˆæ€§',
                'what': 'è¡¡é‡æŒ‰æ—¶å®Œæˆçš„æƒ…å†µ',
                'how': 'æ—¶æ•ˆæ€§ = æŒ‰æ—¶å®Œæˆçš„é‡Œç¨‹ç¢‘æ•° / æ€»é‡Œç¨‹ç¢‘æ•° Ã— 100%',
                'tips': [
                    'æ¯ä¸ªé‡Œç¨‹ç¢‘æœ‰é¢„å®šå®Œæˆæ—¥æœŸ',
                    'æå‰é¢„è­¦é£é™©ï¼ŒåŠæ—¶è°ƒæ•´',
                    'åˆç†å»¶æœŸéœ€æå‰ç”³è¯·',
                ],
            },
        }

        for c in criteria:
            metric_type = c.metric_type if hasattr(c, 'metric_type') else c.get('type', '')
            name = c.name if hasattr(c, 'name') else c.get('name', '')
            threshold = c.threshold if hasattr(c, 'threshold') else c.get('threshold', 0)
            desc = c.description if hasattr(c, 'description') else c.get('description', '')

            exp = metric_explanations.get(metric_type, {})
            title = exp.get('title', f"ğŸ“Œ {name}")

            lines.append(f"### {title}")
            lines.append("")
            lines.append(f"**å®šä¹‰**: {desc}")
            lines.append("")

            threshold_str = f"{threshold * 100:.0f}%" if threshold <= 1 else str(threshold)
            lines.append(f"**éªŒæ”¶é˜ˆå€¼**: â‰¥ **{threshold_str}**")
            lines.append("")

            if 'what' in exp:
                lines.append(f"**å«ä¹‰**: {exp['what']}")
                lines.append("")

            if 'how' in exp:
                lines.append(f"**è®¡ç®—æ–¹å¼**: {exp['how']}")
                lines.append("")

            if 'tips' in exp:
                lines.append("**å®è·µå»ºè®®**:")
                for tip in exp['tips']:
                    lines.append(f"- {tip}")
                lines.append("")

        # éªŒæ”¶æµç¨‹
        lines.append("## éªŒæ”¶æµç¨‹")
        lines.append("")
        lines.append("```")
        lines.append("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        lines.append("â”‚  è‡ªæ£€æäº¤   â”‚ -> â”‚  è´¨æ£€å®¡æ ¸   â”‚ -> â”‚  æœ€ç»ˆéªŒæ”¶   â”‚")
        lines.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
        lines.append("       â”‚                  â”‚                  â”‚")
        lines.append("       v                  v                  v")
        lines.append("  æ ‡æ³¨å›¢é˜Ÿè‡ªæŸ¥      è´¨æ£€å‘˜æŠ½æ£€å®¡æ ¸      é¡¹ç›®è´Ÿè´£äººç¡®è®¤")
        lines.append("  æ‰€æœ‰æŒ‡æ ‡è¾¾æ ‡      å‡ºå…·è´¨æ£€æŠ¥å‘Š       ç­¾å­—äº¤ä»˜")
        lines.append("```")
        lines.append("")

        lines.append("## ä¸è¾¾æ ‡å¤„ç†")
        lines.append("")
        lines.append("| æƒ…å†µ | å¤„ç†æ–¹å¼ |")
        lines.append("|------|----------|")
        lines.append("| å¿…é¡»æŒ‡æ ‡æœªè¾¾æ ‡ | è¿”å·¥ä¿®æ­£ï¼Œç›´è‡³è¾¾æ ‡ |")
        lines.append("| å»ºè®®æŒ‡æ ‡æœªè¾¾æ ‡ | è¯„ä¼°å½±å“ï¼Œåå•†å¤„ç† |")
        lines.append("| å¤šé¡¹æŒ‡æ ‡æœªè¾¾æ ‡ | ç»„ç»‡å¤ç›˜ï¼Œåˆ¶å®šæ”¹è¿›è®¡åˆ’ |")
        lines.append("")

        lines.append("---")
        lines.append("*ç”± DataRecipe ç”Ÿæˆ*")

        return "\n".join(lines)

    def _generate_scripts(self, recipe: DataRecipe, scripts_dir: Path) -> list[str]:
        """ç”Ÿæˆè„šæœ¬æ–‡ä»¶"""
        files = []

        # 01_prepare_data.py
        prepare_script = scripts_dir / "01_prepare_data.py"
        prepare_script.write_text(f'''#!/usr/bin/env python3
"""
æ­¥éª¤ 1: å‡†å¤‡æ•°æ®

å‡†å¤‡ç§å­æ•°æ®å’Œé…ç½®ã€‚
"""

import json
from pathlib import Path

# é…ç½®
OUTPUT_DIR = Path("../data")
OUTPUT_DIR.mkdir(exist_ok=True)

TARGET_SIZE = {recipe.num_examples or 10000}

def main():
    print("å‡†å¤‡æ•°æ®...")

    # åŠ è½½ç§å­æ•°æ®æˆ–åˆ›å»ºåˆå§‹æ•°æ®
    seeds = []

    # TODO: åœ¨æ­¤æ·»åŠ ç§å­æ•°æ®åŠ è½½é€»è¾‘

    # ä¿å­˜ç§å­æ•°æ®
    with open(OUTPUT_DIR / "seed_data.jsonl", "w", encoding="utf-8") as f:
        for seed in seeds:
            f.write(json.dumps(seed, ensure_ascii=False) + "\\n")

    print(f"å‡†å¤‡å®Œæˆï¼Œå…± {{len(seeds)}} æ¡ç§å­æ•°æ®")


if __name__ == "__main__":
    main()
''', encoding="utf-8")
        files.append(str(prepare_script))

        # 02_generate.py
        generate_script = scripts_dir / "02_generate.py"
        model = recipe.teacher_models[0] if recipe.teacher_models else "gpt-4o"
        generate_script.write_text(f'''#!/usr/bin/env python3
"""
æ­¥éª¤ 2: æ•°æ®ç”Ÿæˆ

ä½¿ç”¨ LLM ç”Ÿæˆæ•°æ®ã€‚
"""

import os
import json
from pathlib import Path
from tqdm import tqdm

# é…ç½®
MODEL = "{model}"
INPUT_FILE = Path("../data/seed_data.jsonl")
OUTPUT_FILE = Path("../data/generated.jsonl")

PROMPT_TEMPLATE = """
è¯·æ ¹æ®ä»¥ä¸‹ç§å­æ•°æ®ç”Ÿæˆé«˜è´¨é‡çš„è®­ç»ƒæ ·æœ¬ï¼š

ç§å­æ•°æ®ï¼š
{{seed}}

è¦æ±‚ï¼š
1. ä¿æŒå†…å®¹å‡†ç¡®æ€§
2. æ ¼å¼è§„èŒƒ
3. è¯­è¨€æµç•…

ç”Ÿæˆï¼š
"""


def generate_single(client, seed):
    """ç”Ÿæˆå•æ¡æ•°æ®"""
    prompt = PROMPT_TEMPLATE.format(seed=json.dumps(seed, ensure_ascii=False))

    # TODO: æ ¹æ®å®é™…ä½¿ç”¨çš„ API ä¿®æ”¹
    # response = client.chat.completions.create(
    #     model=MODEL,
    #     messages=[{{"role": "user", "content": prompt}}],
    #     temperature=0.7,
    # )
    # return response.choices[0].message.content

    return None


def main():
    print(f"å¼€å§‹ç”Ÿæˆï¼Œä½¿ç”¨æ¨¡å‹: {{MODEL}}")

    # åŠ è½½ç§å­æ•°æ®
    seeds = []
    if INPUT_FILE.exists():
        with open(INPUT_FILE, "r", encoding="utf-8") as f:
            for line in f:
                seeds.append(json.loads(line))

    print(f"åŠ è½½äº† {{len(seeds)}} æ¡ç§å­æ•°æ®")

    # TODO: åˆå§‹åŒ– API å®¢æˆ·ç«¯
    # from openai import OpenAI
    # client = OpenAI()

    generated = []
    for seed in tqdm(seeds, desc="ç”Ÿæˆä¸­"):
        # result = generate_single(client, seed)
        # if result:
        #     generated.append({{"seed": seed, "generated": result}})
        pass

    # ä¿å­˜ç»“æœ
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        for item in generated:
            f.write(json.dumps(item, ensure_ascii=False) + "\\n")

    print(f"ç”Ÿæˆå®Œæˆï¼Œå…± {{len(generated)}} æ¡")


if __name__ == "__main__":
    main()
''', encoding="utf-8")
        files.append(str(generate_script))

        # 03_validate.py
        validate_script = scripts_dir / "03_validate.py"
        validate_script.write_text('''#!/usr/bin/env python3
"""
æ­¥éª¤ 3: æ•°æ®éªŒè¯

éªŒè¯ç”Ÿæˆçš„æ•°æ®è´¨é‡ã€‚
"""

import json
from pathlib import Path
from collections import Counter

# é…ç½®
INPUT_FILE = Path("../data/generated.jsonl")
OUTPUT_FILE = Path("../data/validated.jsonl")
REPORT_FILE = Path("../data/validation_report.json")

# è´¨é‡è§„åˆ™
MIN_LENGTH = 50
MAX_LENGTH = 10000


def validate_item(item):
    """éªŒè¯å•æ¡æ•°æ®"""
    errors = []
    warnings = []

    text = item.get("generated", "")

    # é•¿åº¦æ£€æŸ¥
    if len(text) < MIN_LENGTH:
        errors.append("æ–‡æœ¬è¿‡çŸ­")
    if len(text) > MAX_LENGTH:
        warnings.append("æ–‡æœ¬è¿‡é•¿")

    # æ ¼å¼æ£€æŸ¥
    if not text.strip():
        errors.append("å†…å®¹ä¸ºç©º")

    return {
        "valid": len(errors) == 0,
        "errors": errors,
        "warnings": warnings,
    }


def main():
    print("å¼€å§‹éªŒè¯...")

    # åŠ è½½æ•°æ®
    items = []
    if INPUT_FILE.exists():
        with open(INPUT_FILE, "r", encoding="utf-8") as f:
            for line in f:
                items.append(json.loads(line))

    print(f"åŠ è½½äº† {len(items)} æ¡æ•°æ®")

    # éªŒè¯
    validated = []
    stats = Counter()

    for item in items:
        result = validate_item(item)
        if result["valid"]:
            validated.append(item)
            stats["passed"] += 1
        else:
            stats["failed"] += 1
            for e in result["errors"]:
                stats[f"error:{e}"] += 1

    # ä¿å­˜éªŒè¯é€šè¿‡çš„æ•°æ®
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        for item in validated:
            f.write(json.dumps(item, ensure_ascii=False) + "\\n")

    # ä¿å­˜æŠ¥å‘Š
    report = {
        "total": len(items),
        "passed": stats["passed"],
        "failed": stats["failed"],
        "pass_rate": stats["passed"] / len(items) if items else 0,
        "details": dict(stats),
    }

    with open(REPORT_FILE, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    print(f"éªŒè¯å®Œæˆ: {stats['passed']}/{len(items)} é€šè¿‡ ({report['pass_rate']*100:.1f}%)")
    print(f"æŠ¥å‘Šä¿å­˜è‡³: {REPORT_FILE}")


if __name__ == "__main__":
    main()
''', encoding="utf-8")
        files.append(str(validate_script))

        return files
