"""Generate output documents from specification analysis."""

import json
import os
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, Dict, List, Optional

from datarecipe.analyzers.spec_analyzer import SpecificationAnalysis


@dataclass
class SpecOutputResult:
    """Result of specification output generation."""

    success: bool = True
    error: str = ""
    output_dir: str = ""
    files_generated: List[str] = field(default_factory=list)


class SpecOutputGenerator:
    """Generate all output documents from specification analysis."""

    def __init__(self, output_dir: str = "./spec_output"):
        self.output_dir = output_dir

    def generate(
        self,
        analysis: SpecificationAnalysis,
        target_size: int = 100,
        region: str = "china",
    ) -> SpecOutputResult:
        """Generate all output documents.

        Args:
            analysis: SpecificationAnalysis from spec analyzer
            target_size: Target dataset size for cost estimation
            region: Region for cost calculation

        Returns:
            SpecOutputResult with generated files
        """
        result = SpecOutputResult()

        try:
            # Create output directory with structure
            project_name = analysis.project_name or "spec_analysis"
            safe_name = project_name.replace("/", "_").replace(" ", "_")
            output_dir = os.path.join(self.output_dir, safe_name)

            # Create subdirectories
            subdirs = {
                "decision": "01_å†³ç­–å‚è€ƒ",
                "project": "02_é¡¹ç›®ç®¡ç†",
                "annotation": "03_æ ‡æ³¨è§„èŒƒ",
                "guide": "04_å¤åˆ»æŒ‡å—",
                "cost": "05_æˆæœ¬åˆ†æ",
                "data": "06_åŸå§‹æ•°æ®",
            }
            for key, subdir in subdirs.items():
                os.makedirs(os.path.join(output_dir, subdir), exist_ok=True)

            result.output_dir = output_dir

            # Generate each document
            self._generate_annotation_spec(analysis, output_dir, subdirs, result)
            self._generate_executive_summary(analysis, output_dir, subdirs, target_size, region, result)
            self._generate_milestone_plan(analysis, output_dir, subdirs, target_size, region, result)
            self._generate_cost_breakdown(analysis, output_dir, subdirs, target_size, region, result)
            self._generate_industry_benchmark(analysis, output_dir, subdirs, target_size, region, result)
            self._generate_raw_analysis(analysis, output_dir, subdirs, result)
            self._generate_readme(analysis, output_dir, subdirs, result)

        except Exception as e:
            result.success = False
            result.error = str(e)

        return result

    def _generate_annotation_spec(
        self,
        analysis: SpecificationAnalysis,
        output_dir: str,
        subdirs: dict,
        result: SpecOutputResult,
    ):
        """Generate ANNOTATION_SPEC.md."""
        lines = []

        lines.append(f"# {analysis.project_name} æ ‡æ³¨è§„èŒƒ")
        lines.append("")
        lines.append(f"> ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
        lines.append(f"> æ•°æ®ç±»å‹: {analysis.dataset_type}")
        if analysis.has_images:
            lines.append(f"> åŒ…å«å›¾ç‰‡: æ˜¯ ({analysis.image_count} å¼ )")
        lines.append("")
        lines.append("---")
        lines.append("")

        # Section 1: Task Type Description
        lines.append("## ä¸€ã€é¢˜ç›®ç±»å‹æè¿°")
        lines.append("")
        lines.append(f"**ä»»åŠ¡åç§°**: {analysis.task_type}")
        lines.append("")
        lines.append(f"**ä»»åŠ¡è¯´æ˜**: {analysis.task_description}")
        lines.append("")

        if analysis.cognitive_requirements:
            lines.append("**è®¤çŸ¥è¦æ±‚**:")
            for req in analysis.cognitive_requirements:
                lines.append(f"- {req}")
            lines.append("")

        if analysis.reasoning_chain:
            lines.append("**æ¨ç†é“¾**:")
            lines.append("")
            lines.append("```")
            lines.append(" â†’ ".join(analysis.reasoning_chain))
            lines.append("```")
            lines.append("")

        # Section 2: Data Requirements
        lines.append("## äºŒã€æ•°æ®è¦æ±‚")
        lines.append("")

        if analysis.data_requirements:
            for i, req in enumerate(analysis.data_requirements, 1):
                lines.append(f"{i}. {req}")
            lines.append("")

        # Section 3: Quality Constraints
        lines.append("## ä¸‰ã€è´¨é‡çº¦æŸ")
        lines.append("")

        if analysis.forbidden_items:
            lines.append("### ç¦æ­¢é¡¹ âš ï¸")
            lines.append("")
            for item in analysis.forbidden_items:
                lines.append(f"- âŒ {item}")
            lines.append("")

        if analysis.quality_constraints:
            lines.append("### è´¨é‡æ ‡å‡†")
            lines.append("")
            for constraint in analysis.quality_constraints:
                lines.append(f"- {constraint}")
            lines.append("")

        if analysis.difficulty_criteria:
            lines.append("### éš¾åº¦éªŒè¯")
            lines.append("")
            lines.append(f"{analysis.difficulty_criteria}")
            lines.append("")

        # Section 4: Data Structure
        lines.append("## å››ã€æ•°æ®ç»“æ„")
        lines.append("")

        if analysis.fields:
            lines.append("| å­—æ®µå | ç±»å‹ | å¿…å¡« | è¯´æ˜ |")
            lines.append("|--------|------|------|------|")
            for f in analysis.fields:
                name = f.get("name", "")
                ftype = f.get("type", "string")
                required = "æ˜¯" if f.get("required", True) else "å¦"
                desc = f.get("description", "")
                lines.append(f"| {name} | {ftype} | {required} | {desc} |")
            lines.append("")

        if analysis.field_requirements:
            lines.append("### å­—æ®µè¯¦ç»†è¦æ±‚")
            lines.append("")
            for fname, freq in analysis.field_requirements.items():
                lines.append(f"**{fname}**: {freq}")
                lines.append("")

        # Section 5: Examples
        lines.append("## äº”ã€ç¤ºä¾‹")
        lines.append("")

        for i, example in enumerate(analysis.examples[:3], 1):
            lines.append(f"### ç¤ºä¾‹ {i}")
            lines.append("")

            if example.get("has_image"):
                lines.append("**[åŒ…å«å›¾ç‰‡]**")
                lines.append("")

            if example.get("question"):
                lines.append("**é¢˜ç›®**:")
                lines.append("")
                lines.append(f"> {example['question']}")
                lines.append("")

            if example.get("answer"):
                lines.append(f"**ç­”æ¡ˆ**: {example['answer']}")
                lines.append("")

            if example.get("scoring_rubric"):
                lines.append("**æ‰“åˆ†æ ‡å‡†**:")
                lines.append("")
                lines.append(f"{example['scoring_rubric']}")
                lines.append("")

            lines.append("---")
            lines.append("")

        # Section 6: Scoring Rubric
        if analysis.scoring_rubric:
            lines.append("## å…­ã€æ‰“åˆ†æ ‡å‡†")
            lines.append("")
            lines.append("| åˆ†æ•° | æ ‡å‡† |")
            lines.append("|------|------|")
            for rubric in analysis.scoring_rubric:
                score = rubric.get("score", "")
                criteria = rubric.get("criteria", "")
                lines.append(f"| {score} | {criteria} |")
            lines.append("")

        lines.append("---")
        lines.append("")
        lines.append("*æœ¬è§„èŒƒç”± DataRecipe ä»éœ€æ±‚æ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆ*")

        # Write file
        spec_path = os.path.join(output_dir, subdirs["annotation"], "ANNOTATION_SPEC.md")
        with open(spec_path, "w", encoding="utf-8") as f:
            f.write("\n".join(lines))
        result.files_generated.append(f"{subdirs['annotation']}/ANNOTATION_SPEC.md")

        # Also save as JSON
        spec_dict = {
            "project_name": analysis.project_name,
            "dataset_type": analysis.dataset_type,
            "task_type": analysis.task_type,
            "task_description": analysis.task_description,
            "cognitive_requirements": analysis.cognitive_requirements,
            "reasoning_chain": analysis.reasoning_chain,
            "data_requirements": analysis.data_requirements,
            "quality_constraints": analysis.quality_constraints,
            "forbidden_items": analysis.forbidden_items,
            "difficulty_criteria": analysis.difficulty_criteria,
            "fields": analysis.fields,
            "field_requirements": analysis.field_requirements,
            "examples": analysis.examples,
            "scoring_rubric": analysis.scoring_rubric,
        }
        json_path = os.path.join(output_dir, subdirs["annotation"], "annotation_spec.json")
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(spec_dict, f, indent=2, ensure_ascii=False)
        result.files_generated.append(f"{subdirs['annotation']}/annotation_spec.json")

    def _generate_executive_summary(
        self,
        analysis: SpecificationAnalysis,
        output_dir: str,
        subdirs: dict,
        target_size: int,
        region: str,
        result: SpecOutputResult,
    ):
        """Generate EXECUTIVE_SUMMARY.md."""
        # Calculate cost estimates
        cost_per_item = self._estimate_cost_per_item(analysis, region)
        total_cost = cost_per_item * target_size
        human_cost = total_cost * (analysis.estimated_human_percentage / 100)
        api_cost = total_cost - human_cost

        # Determine recommendation
        if analysis.estimated_difficulty == "expert":
            recommendation = "æœ‰æ¡ä»¶æ¨è"
            rec_icon = "ğŸŸ¡"
            score = 5.5
        elif analysis.estimated_difficulty == "hard":
            recommendation = "æ¨è"
            rec_icon = "ğŸŸ¢"
            score = 6.5
        else:
            recommendation = "å¼ºçƒˆæ¨è"
            rec_icon = "ğŸŸ¢"
            score = 7.5

        lines = []
        lines.append(f"# {analysis.project_name} æ‰§è¡Œæ‘˜è¦")
        lines.append("")
        lines.append(f"> ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
        lines.append(f"> æ•°æ®é›†ç±»å‹: {analysis.dataset_type}")
        lines.append(f"> ç›®æ ‡è§„æ¨¡: {target_size} æ¡")
        lines.append("")
        lines.append("---")
        lines.append("")

        # Decision box
        lines.append(f"## {rec_icon} å†³ç­–å»ºè®®: {recommendation}")
        lines.append("")
        lines.append(f"**è¯„åˆ†**: {score}/10")
        lines.append("")
        lines.append(f"**ç†ç”±**: æ•°æ®é›†ä»·å€¼è‰¯å¥½ (è¯„åˆ† {score}/10)ï¼Œ{recommendation}")
        lines.append("")

        # Key metrics
        lines.append("### å…³é”®æŒ‡æ ‡")
        lines.append("")
        lines.append("| æŒ‡æ ‡ | æ•°å€¼ |")
        lines.append("|------|------|")
        lines.append(f"| æ€»æˆæœ¬ | ${total_cost:,.0f} |")
        lines.append(f"| äººå·¥æˆæœ¬ | ${human_cost:,.0f} ({analysis.estimated_human_percentage:.0f}%) |")
        lines.append(f"| éš¾åº¦ | {analysis.estimated_difficulty} |")
        lines.append(f"| é¢†åŸŸ | {analysis.estimated_domain} |")
        lines.append("")

        # Use cases
        lines.append("---")
        lines.append("")
        lines.append("## ç”¨é€”ä¸ä»·å€¼")
        lines.append("")
        lines.append(f"**ä¸»è¦ç”¨é€”**: {analysis.description or analysis.task_description}")
        lines.append("")

        # Risks
        lines.append("---")
        lines.append("")
        lines.append("## é£é™©è¯„ä¼°")
        lines.append("")
        lines.append("| é£é™©ç­‰çº§ | æè¿° | ç¼“è§£æªæ–½ |")
        lines.append("|----------|------|----------|")

        if "AI" in str(analysis.forbidden_items) or "ai" in str(analysis.forbidden_items).lower():
            lines.append("| é«˜ | ç¦æ­¢ä½¿ç”¨AIç”Ÿæˆå†…å®¹ï¼Œå…¨äººå·¥æˆæœ¬é«˜ | ä¸¥æ ¼å®¡æ ¸æµç¨‹ï¼Œç¡®ä¿æ•°æ®åŸåˆ›æ€§ |")

        if analysis.estimated_difficulty in ["hard", "expert"]:
            lines.append("| ä¸­ | éš¾åº¦è¾ƒé«˜ï¼Œéœ€è¦ä¸“ä¸šäººå‘˜ | æå‰å‚¨å¤‡äººæ‰ï¼ŒåŠ å¼ºåŸ¹è®­ |")

        if analysis.has_images:
            lines.append("| ä¸­ | åŒ…å«å›¾ç‰‡ï¼Œåˆ¶ä½œæˆæœ¬è¾ƒé«˜ | å»ºç«‹å›¾ç‰‡ç´ æåº“ï¼Œè§„èŒƒåˆ¶ä½œæµç¨‹ |")

        lines.append("| ä½ | æ ‡æ³¨è´¨é‡å¯èƒ½æ³¢åŠ¨ | å»ºç«‹QAæµç¨‹ï¼Œå®šæœŸæ ¡å‡† |")
        lines.append("")

        # Similar datasets
        if analysis.similar_datasets:
            lines.append("---")
            lines.append("")
            lines.append("## ç±»ä¼¼æ•°æ®é›†")
            lines.append("")
            for ds in analysis.similar_datasets:
                lines.append(f"- {ds}")
            lines.append("")

        lines.append("---")
        lines.append("")
        lines.append("*æœ¬æ‘˜è¦ç”± DataRecipe ä»éœ€æ±‚æ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆ*")

        # Write file
        path = os.path.join(output_dir, subdirs["decision"], "EXECUTIVE_SUMMARY.md")
        with open(path, "w", encoding="utf-8") as f:
            f.write("\n".join(lines))
        result.files_generated.append(f"{subdirs['decision']}/EXECUTIVE_SUMMARY.md")

        # Save JSON
        summary_dict = {
            "project_name": analysis.project_name,
            "recommendation": recommendation,
            "score": score,
            "total_cost": total_cost,
            "human_cost": human_cost,
            "api_cost": api_cost,
            "human_percentage": analysis.estimated_human_percentage,
            "difficulty": analysis.estimated_difficulty,
            "domain": analysis.estimated_domain,
        }
        json_path = os.path.join(output_dir, subdirs["decision"], "executive_summary.json")
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(summary_dict, f, indent=2, ensure_ascii=False)
        result.files_generated.append(f"{subdirs['decision']}/executive_summary.json")

    def _generate_milestone_plan(
        self,
        analysis: SpecificationAnalysis,
        output_dir: str,
        subdirs: dict,
        target_size: int,
        region: str,
        result: SpecOutputResult,
    ):
        """Generate MILESTONE_PLAN.md."""
        # Estimate duration based on difficulty
        difficulty_days = {
            "easy": 14,
            "medium": 21,
            "hard": 30,
            "expert": 45,
        }
        total_days = difficulty_days.get(analysis.estimated_difficulty, 30)

        lines = []
        lines.append(f"# {analysis.project_name} é‡Œç¨‹ç¢‘è®¡åˆ’")
        lines.append("")
        lines.append(f"> ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
        lines.append(f"> æ•°æ®é›†ç±»å‹: {analysis.dataset_type}")
        lines.append(f"> ç›®æ ‡è§„æ¨¡: {target_size} æ¡")
        lines.append(f"> é¢„ä¼°å·¥æœŸ: {total_days} å·¥ä½œæ—¥")
        lines.append("")
        lines.append("---")
        lines.append("")

        # Progress visualization
        lines.append("## é¡¹ç›®æ¦‚è§ˆ")
        lines.append("")
        lines.append("```")
        lines.append("é˜¶æ®µè¿›åº¦:")
        lines.append("M1 é¡¹ç›®å¯åŠ¨ä¸è§„èŒƒåˆ¶å®š    â–ˆâ–ˆâ–ˆ                  15%")
        lines.append("M2 è¯•ç‚¹æ ‡æ³¨ä¸æ ‡å‡†æ ¡å‡†    â–ˆâ–ˆ                   10%")
        lines.append("M3 ä¸»ä½“æ ‡æ³¨ - ç¬¬ä¸€æ‰¹æ¬¡  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               30%")
        lines.append("M4 ä¸»ä½“æ ‡æ³¨ - ç¬¬äºŒæ‰¹æ¬¡  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               30%")
        lines.append("M5 è´¨é‡å®¡æ ¸ä¸äº¤ä»˜      â–ˆâ–ˆâ–ˆ                  15%")
        lines.append("```")
        lines.append("")

        # Team composition
        lines.append("### å›¢é˜Ÿé…ç½®")
        lines.append("")
        lines.append("| è§’è‰² | äººæ•° | è¯´æ˜ |")
        lines.append("|------|------|------|")
        lines.append("| é¡¹ç›®ç»ç† | 1 | æ•´ä½“åè°ƒ |")

        if analysis.estimated_difficulty in ["hard", "expert"]:
            lines.append("| é¢†åŸŸä¸“å®¶ | 2-3 | è§„åˆ™è®¾è®¡ã€è´¨é‡æŠŠæ§ |")
        else:
            lines.append("| é¢†åŸŸä¸“å®¶ | 1-2 | è§„åˆ™è®¾è®¡ã€è´¨é‡æŠŠæ§ |")

        lines.append("| QA | 1-2 | è´¨é‡æŠ½æ£€ |")

        if analysis.has_images:
            lines.append("| å›¾ç‰‡åˆ¶ä½œ | 2-3 | åŸåˆ›å›¾ç‰‡è®¾è®¡ |")

        annotator_count = max(2, target_size // 50)
        lines.append(f"| æ ‡æ³¨å‘˜ | {annotator_count}-{annotator_count + 2} | æ•°æ®ç”Ÿäº§ |")
        lines.append("")

        # Milestones
        lines.append("---")
        lines.append("")
        lines.append("## é‡Œç¨‹ç¢‘è¯¦æƒ…")
        lines.append("")

        milestones = [
            ("M1", "é¡¹ç›®å¯åŠ¨ä¸è§„èŒƒåˆ¶å®š", "å®Œæˆé¡¹ç›®åˆå§‹åŒ–ã€åˆ¶å®šæ ‡æ³¨è§„èŒƒå’Œè´¨é‡æ ‡å‡†",
             ["æ ‡æ³¨æŒ‡å—æ–‡æ¡£ v1.0", "Schema å®šä¹‰ä¸ç¤ºä¾‹", "æ ‡æ³¨å·¥å…·é…ç½®å®Œæˆ", "å›¢é˜ŸåŸ¹è®­ææ–™"]),
            ("M2", "è¯•ç‚¹æ ‡æ³¨ä¸æ ‡å‡†æ ¡å‡†", "å®Œæˆè¯•ç‚¹æ‰¹æ¬¡ï¼ŒéªŒè¯æ ‡æ³¨æµç¨‹å’Œè´¨é‡æ ‡å‡†",
             [f"è¯•ç‚¹æ•°æ® ({max(5, target_size // 20)} æ¡)", "æ ‡æ³¨ä¸€è‡´æ€§æŠ¥å‘Š", "æµç¨‹é—®é¢˜æ¸…å•ä¸è§£å†³æ–¹æ¡ˆ"]),
            ("M3", "ä¸»ä½“æ ‡æ³¨ - ç¬¬ä¸€æ‰¹æ¬¡", "å®Œæˆ 40% çš„æ ‡æ³¨é‡",
             [f"å·²æ ‡æ³¨æ•°æ® ({int(target_size * 0.4)} æ¡)", "è´¨é‡å‘¨æŠ¥"]),
            ("M4", "ä¸»ä½“æ ‡æ³¨ - ç¬¬äºŒæ‰¹æ¬¡", "å®Œæˆå‰©ä½™ 60% çš„æ ‡æ³¨é‡",
             [f"å·²æ ‡æ³¨æ•°æ® ({target_size} æ¡)", "è´¨é‡å‘¨æŠ¥"]),
            ("M5", "è´¨é‡å®¡æ ¸ä¸äº¤ä»˜", "å®Œæˆæœ€ç»ˆè´¨é‡å®¡æ ¸å’Œæ•°æ®äº¤ä»˜",
             ["æœ€ç»ˆæ•°æ®é›†", "è´¨é‡æŠ¥å‘Š", "æ•°æ®æ–‡æ¡£"]),
        ]

        for mid, name, desc, deliverables in milestones:
            lines.append(f"### {mid}: {name}")
            lines.append("")
            lines.append(f"**æè¿°**: {desc}")
            lines.append("")
            lines.append("**äº¤ä»˜ç‰©**:")
            for d in deliverables:
                lines.append(f"- [ ] {d}")
            lines.append("")

        # Acceptance criteria
        lines.append("---")
        lines.append("")
        lines.append("## éªŒæ”¶æ ‡å‡†")
        lines.append("")
        lines.append("| ç±»åˆ« | æŒ‡æ ‡ | é˜ˆå€¼ |")
        lines.append("|------|------|------|")
        lines.append("| ä¸€è‡´æ€§ | Cohen's Kappa | â‰¥ 0.7 |")
        lines.append("| å‡†ç¡®æ€§ | ä¸“å®¶å®¡æ ¸é€šè¿‡ç‡ | â‰¥ 95% |")
        lines.append("| å®Œæ•´æ€§ | ç©ºå€¼ç‡ | = 0% |")

        if analysis.difficulty_criteria:
            lines.append(f"| éš¾åº¦ | {analysis.difficulty_criteria[:30]}... | é€šè¿‡éªŒè¯ |")

        lines.append("")

        # Risks
        lines.append("---")
        lines.append("")
        lines.append("## é£é™©ç®¡ç†")
        lines.append("")

        if analysis.forbidden_items:
            lines.append("### R1: æ•°æ®åˆè§„æ€§é£é™©")
            lines.append("")
            lines.append("- **æ¦‚ç‡**: ğŸŸ¡ ä¸­")
            lines.append("- **å½±å“**: ğŸ”´ é«˜")
            lines.append("- **ç¼“è§£æªæ–½**: ä¸¥æ ¼å®¡æ ¸æµç¨‹ï¼Œç¡®ä¿ä¸å«AIå†…å®¹")
            lines.append("")

        lines.append("### R2: è´¨é‡ä¸ç¨³å®šé£é™©")
        lines.append("")
        lines.append("- **æ¦‚ç‡**: ğŸŸ¡ ä¸­")
        lines.append("- **å½±å“**: ğŸŸ¡ ä¸­")
        lines.append("- **ç¼“è§£æªæ–½**: åŠ å¼ºåŸ¹è®­ï¼Œå®šæœŸæ ¡å‡†ï¼Œå»ºç«‹QAæµç¨‹")
        lines.append("")

        lines.append("---")
        lines.append("")
        lines.append("*æœ¬è®¡åˆ’ç”± DataRecipe ä»éœ€æ±‚æ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆ*")

        # Write file
        path = os.path.join(output_dir, subdirs["project"], "MILESTONE_PLAN.md")
        with open(path, "w", encoding="utf-8") as f:
            f.write("\n".join(lines))
        result.files_generated.append(f"{subdirs['project']}/MILESTONE_PLAN.md")

        # Save JSON
        plan_dict = {
            "project_name": analysis.project_name,
            "target_size": target_size,
            "total_days": total_days,
            "milestones": [
                {"id": mid, "name": name, "description": desc, "deliverables": deliverables}
                for mid, name, desc, deliverables in milestones
            ],
        }
        json_path = os.path.join(output_dir, subdirs["project"], "milestone_plan.json")
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(plan_dict, f, indent=2, ensure_ascii=False)
        result.files_generated.append(f"{subdirs['project']}/milestone_plan.json")

    def _generate_cost_breakdown(
        self,
        analysis: SpecificationAnalysis,
        output_dir: str,
        subdirs: dict,
        target_size: int,
        region: str,
        result: SpecOutputResult,
    ):
        """Generate COST_BREAKDOWN.md."""
        cost_per_item = self._estimate_cost_per_item(analysis, region)
        total_cost = cost_per_item * target_size
        human_cost = total_cost * (analysis.estimated_human_percentage / 100)

        # Design phase (fixed costs)
        design_cost = 2000 if analysis.estimated_difficulty in ["hard", "expert"] else 1200

        # Production phase (variable costs)
        production_cost = human_cost * 0.7

        # QA phase
        qa_cost = human_cost * 0.2

        # Contingency
        contingency = total_cost * 0.15

        grand_total = design_cost + production_cost + qa_cost + contingency

        lines = []
        lines.append(f"# {analysis.project_name} æˆæœ¬æ˜ç»†")
        lines.append("")
        lines.append(f"> ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
        lines.append(f"> ç›®æ ‡è§„æ¨¡: {target_size} æ¡")
        lines.append(f"> å•æ¡æˆæœ¬: ${cost_per_item:.2f}")
        lines.append("")
        lines.append("---")
        lines.append("")

        lines.append("## é˜¶æ®µä¸€ï¼šè®¾è®¡é˜¶æ®µï¼ˆå›ºå®šæˆæœ¬ï¼‰")
        lines.append("")
        lines.append("| é¡¹ç›® | æˆæœ¬ |")
        lines.append("|------|------|")
        lines.append(f"| Schema è®¾è®¡ | ${design_cost * 0.3:.0f} |")
        lines.append(f"| æ ‡æ³¨æŒ‡å—ç¼–å†™ | ${design_cost * 0.4:.0f} |")
        lines.append(f"| è¯•ç‚¹æµ‹è¯• | ${design_cost * 0.2:.0f} |")
        lines.append(f"| å·¥å…·é…ç½® | ${design_cost * 0.1:.0f} |")
        lines.append(f"| **å°è®¡** | **${design_cost:.0f}** |")
        lines.append("")

        lines.append("## é˜¶æ®µäºŒï¼šç”Ÿäº§é˜¶æ®µï¼ˆå˜åŠ¨æˆæœ¬ï¼‰")
        lines.append("")
        lines.append("| é¡¹ç›® | æˆæœ¬ | å•ä»· |")
        lines.append("|------|------|------|")
        lines.append(f"| äººå·¥æ ‡æ³¨ | ${production_cost:.0f} | ${production_cost / target_size:.2f}/æ¡ |")

        if analysis.has_images:
            img_cost = target_size * 5  # $5 per image
            lines.append(f"| å›¾ç‰‡åˆ¶ä½œ | ${img_cost:.0f} | $5/å¼  |")
            production_cost += img_cost

        lines.append(f"| **å°è®¡** | **${production_cost:.0f}** | |")
        lines.append("")

        lines.append("## é˜¶æ®µä¸‰ï¼šè´¨é‡é˜¶æ®µ")
        lines.append("")
        lines.append("| é¡¹ç›® | æˆæœ¬ |")
        lines.append("|------|------|")
        lines.append(f"| QA æŠ½æ£€ | ${qa_cost * 0.6:.0f} |")
        lines.append(f"| è¿”å·¥ä¿®æ­£ | ${qa_cost * 0.3:.0f} |")
        lines.append(f"| ä¸“å®¶å¤æ ¸ | ${qa_cost * 0.1:.0f} |")
        lines.append(f"| **å°è®¡** | **${qa_cost:.0f}** |")
        lines.append("")

        lines.append("## æ±‡æ€»")
        lines.append("")
        lines.append("| é˜¶æ®µ | æˆæœ¬ | å æ¯” |")
        lines.append("|------|------|------|")
        lines.append(f"| è®¾è®¡é˜¶æ®µ | ${design_cost:.0f} | {design_cost / grand_total * 100:.1f}% |")
        lines.append(f"| ç”Ÿäº§é˜¶æ®µ | ${production_cost:.0f} | {production_cost / grand_total * 100:.1f}% |")
        lines.append(f"| è´¨é‡é˜¶æ®µ | ${qa_cost:.0f} | {qa_cost / grand_total * 100:.1f}% |")
        lines.append(f"| é£é™©é¢„ç•™ (15%) | ${contingency:.0f} | 15% |")
        lines.append(f"| **æ€»è®¡** | **${grand_total:.0f}** | 100% |")
        lines.append("")

        lines.append("---")
        lines.append("")
        lines.append("*æœ¬æˆæœ¬ä¼°ç®—ç”± DataRecipe ä»éœ€æ±‚æ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆ*")

        # Write file
        path = os.path.join(output_dir, subdirs["cost"], "COST_BREAKDOWN.md")
        with open(path, "w", encoding="utf-8") as f:
            f.write("\n".join(lines))
        result.files_generated.append(f"{subdirs['cost']}/COST_BREAKDOWN.md")

        # Save JSON
        cost_dict = {
            "target_size": target_size,
            "cost_per_item": cost_per_item,
            "design_cost": design_cost,
            "production_cost": production_cost,
            "qa_cost": qa_cost,
            "contingency": contingency,
            "grand_total": grand_total,
        }
        json_path = os.path.join(output_dir, subdirs["cost"], "cost_breakdown.json")
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(cost_dict, f, indent=2, ensure_ascii=False)
        result.files_generated.append(f"{subdirs['cost']}/cost_breakdown.json")

    def _generate_industry_benchmark(
        self,
        analysis: SpecificationAnalysis,
        output_dir: str,
        subdirs: dict,
        target_size: int,
        region: str,
        result: SpecOutputResult,
    ):
        """Generate INDUSTRY_BENCHMARK.md."""
        cost_per_item = self._estimate_cost_per_item(analysis, region)
        total_cost = cost_per_item * target_size

        # Get benchmark data
        benchmarks = {
            "evaluation": {"min": 5, "avg": 15, "max": 50},
            "multimodal": {"min": 10, "avg": 25, "max": 80},
            "reasoning": {"min": 8, "avg": 20, "max": 60},
        }
        benchmark = benchmarks.get(analysis.dataset_type, {"min": 5, "avg": 15, "max": 50})

        lines = []
        lines.append(f"# {analysis.project_name} è¡Œä¸šåŸºå‡†å¯¹æ¯”")
        lines.append("")
        lines.append(f"> ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
        lines.append(f"> æ•°æ®é›†ç±»å‹: {analysis.dataset_type}")
        lines.append("")
        lines.append("---")
        lines.append("")

        lines.append("## é¡¹ç›®æ¦‚å†µ")
        lines.append("")
        lines.append("| æŒ‡æ ‡ | æ•°å€¼ |")
        lines.append("|------|------|")
        lines.append(f"| æ ·æœ¬æ•°é‡ | {target_size:,} |")
        lines.append(f"| æ€»æˆæœ¬ | ${total_cost:,.0f} |")
        lines.append(f"| å•æ¡æˆæœ¬ | ${cost_per_item:.2f} |")
        lines.append(f"| äººå·¥å æ¯” | {analysis.estimated_human_percentage:.0f}% |")
        lines.append("")

        lines.append("## è¡Œä¸šåŸºå‡†")
        lines.append("")
        lines.append(f"**æ•°æ®ç±»å‹**: {analysis.dataset_type}")
        lines.append("")
        lines.append("### å•æ¡æˆæœ¬åŸºå‡†")
        lines.append("")
        lines.append("```")
        lines.append(f"æœ€ä½: ${benchmark['min']:.2f}/æ¡")
        lines.append(f"å¹³å‡: ${benchmark['avg']:.2f}/æ¡")
        lines.append(f"æœ€é«˜: ${benchmark['max']:.2f}/æ¡")
        lines.append("```")
        lines.append("")

        # Rating
        if cost_per_item < benchmark["avg"]:
            rating = "ğŸŸ¢ æˆæœ¬ä½äºè¡Œä¸šå¹³å‡"
        elif cost_per_item <= benchmark["max"]:
            rating = "ğŸŸ¡ æˆæœ¬åœ¨åˆç†èŒƒå›´å†…"
        else:
            rating = "ğŸ”´ æˆæœ¬é«˜äºè¡Œä¸šåŸºå‡†"

        lines.append(f"**æˆæœ¬è¯„çº§**: {rating}")
        lines.append("")

        lines.append("---")
        lines.append("")
        lines.append("*åŸºå‡†æ•°æ®æ¥æºäºè¡Œä¸šè°ƒç ”ï¼Œä»…ä¾›å‚è€ƒ*")

        # Write file
        path = os.path.join(output_dir, subdirs["project"], "INDUSTRY_BENCHMARK.md")
        with open(path, "w", encoding="utf-8") as f:
            f.write("\n".join(lines))
        result.files_generated.append(f"{subdirs['project']}/INDUSTRY_BENCHMARK.md")

    def _generate_raw_analysis(
        self,
        analysis: SpecificationAnalysis,
        output_dir: str,
        subdirs: dict,
        result: SpecOutputResult,
    ):
        """Generate raw analysis JSON."""
        path = os.path.join(output_dir, subdirs["data"], "spec_analysis.json")
        with open(path, "w", encoding="utf-8") as f:
            json.dump(analysis.to_dict(), f, indent=2, ensure_ascii=False)
        result.files_generated.append(f"{subdirs['data']}/spec_analysis.json")

    def _generate_readme(
        self,
        analysis: SpecificationAnalysis,
        output_dir: str,
        subdirs: dict,
        result: SpecOutputResult,
    ):
        """Generate README.md."""
        lines = []
        lines.append(f"# {analysis.project_name} åˆ†æäº§å‡º")
        lines.append("")
        lines.append(f"> ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
        lines.append(f"> æ•°æ®ç±»å‹: {analysis.dataset_type}")
        lines.append(f"> æ¥æº: éœ€æ±‚æ–‡æ¡£åˆ†æ")
        lines.append("")
        lines.append("## ç›®å½•ç»“æ„")
        lines.append("")
        lines.append("```")
        lines.append(f"{os.path.basename(output_dir)}/")
        lines.append("â”œâ”€â”€ README.md                    # æœ¬æ–‡ä»¶")
        lines.append("â”‚")
        lines.append(f"â”œâ”€â”€ {subdirs['decision']}/           # ğŸ‘” å†³ç­–å±‚")
        lines.append("â”‚   â””â”€â”€ EXECUTIVE_SUMMARY.md     # æ‰§è¡Œæ‘˜è¦")
        lines.append("â”‚")
        lines.append(f"â”œâ”€â”€ {subdirs['project']}/           # ğŸ“‹ é¡¹ç›®ç®¡ç†")
        lines.append("â”‚   â”œâ”€â”€ MILESTONE_PLAN.md        # é‡Œç¨‹ç¢‘è®¡åˆ’")
        lines.append("â”‚   â””â”€â”€ INDUSTRY_BENCHMARK.md    # è¡Œä¸šåŸºå‡†")
        lines.append("â”‚")
        lines.append(f"â”œâ”€â”€ {subdirs['annotation']}/           # ğŸ“ æ ‡æ³¨å›¢é˜Ÿ")
        lines.append("â”‚   â””â”€â”€ ANNOTATION_SPEC.md       # æ ‡æ³¨è§„èŒƒ")
        lines.append("â”‚")
        lines.append(f"â”œâ”€â”€ {subdirs['cost']}/           # ğŸ’° æˆæœ¬åˆ†æ")
        lines.append("â”‚   â””â”€â”€ COST_BREAKDOWN.md        # æˆæœ¬æ˜ç»†")
        lines.append("â”‚")
        lines.append(f"â””â”€â”€ {subdirs['data']}/           # ğŸ“Š åŸå§‹æ•°æ®")
        lines.append("    â””â”€â”€ spec_analysis.json       # åˆ†ææ•°æ®")
        lines.append("```")
        lines.append("")
        lines.append("## å¿«é€Ÿå¯¼èˆª")
        lines.append("")
        lines.append("| ç›®æ ‡ | æŸ¥çœ‹æ–‡ä»¶ |")
        lines.append("|------|----------|")
        lines.append(f"| **å¿«é€Ÿå†³ç­–** | `{subdirs['decision']}/EXECUTIVE_SUMMARY.md` |")
        lines.append(f"| **é¡¹ç›®è§„åˆ’** | `{subdirs['project']}/MILESTONE_PLAN.md` |")
        lines.append(f"| **æ ‡æ³¨å¤–åŒ…** | `{subdirs['annotation']}/ANNOTATION_SPEC.md` |")
        lines.append(f"| **æˆæœ¬é¢„ç®—** | `{subdirs['cost']}/COST_BREAKDOWN.md` |")
        lines.append("")
        lines.append("---")
        lines.append("")
        lines.append("*ç”± DataRecipe analyze-spec å‘½ä»¤ç”Ÿæˆ*")

        path = os.path.join(output_dir, "README.md")
        with open(path, "w", encoding="utf-8") as f:
            f.write("\n".join(lines))
        result.files_generated.append("README.md")

    def _estimate_cost_per_item(self, analysis: SpecificationAnalysis, region: str) -> float:
        """Estimate cost per item based on analysis."""
        # Base cost by difficulty
        base_costs = {
            "easy": 5,
            "medium": 10,
            "hard": 20,
            "expert": 40,
        }
        base = base_costs.get(analysis.estimated_difficulty, 15)

        # Multipliers
        multiplier = 1.0

        # Image multiplier
        if analysis.has_images:
            multiplier *= 1.5

        # Complexity multiplier (based on reasoning chain length)
        if len(analysis.reasoning_chain) > 3:
            multiplier *= 1.3

        # Forbidden items multiplier (all human = more expensive)
        if analysis.forbidden_items:
            multiplier *= 1.2

        # Region adjustment
        if region == "china":
            multiplier *= 0.6  # China is cheaper
        elif region == "us":
            multiplier *= 1.0

        return base * multiplier
