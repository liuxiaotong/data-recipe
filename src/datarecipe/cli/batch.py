"""Batch analysis commands."""

import json

import click

from datarecipe.cli._helpers import console


@click.command("batch-from-radar")
@click.argument("radar_report")
@click.option("--output-dir", "-o", default="./projects", help="Output directory")
@click.option("--sample-size", "-n", default=200, help="Number of samples per dataset")
@click.option("--limit", "-l", default=0, type=int, help="Max datasets to analyze (0 = all)")
@click.option("--orgs", help="Filter by orgs (comma-separated)")
@click.option("--categories", help="Filter by categories (comma-separated)")
@click.option("--min-downloads", default=0, type=int, help="Minimum downloads")
@click.option("--use-llm", is_flag=True, help="Use LLM for unknown types")
@click.option("--region", "-r", default="china", help="Region for cost calculation")
@click.option(
    "--sort-by",
    type=click.Choice(["downloads", "name", "category"]),
    default="downloads",
    help="Sort datasets by",
)
@click.option("--incremental", "-i", is_flag=True, help="Skip already analyzed datasets")
@click.option("--parallel", "-p", default=1, type=int, help="Parallel workers (1=sequential)")
def batch_from_radar(
    radar_report: str,
    output_dir: str,
    sample_size: int,
    limit: int,
    orgs: str,
    categories: str,
    min_downloads: int,
    use_llm: bool,
    region: str,
    sort_by: str,
    incremental: bool,
    parallel: int,
):
    """
    Batch analyze datasets from an ai-dataset-radar report.

    Reads a radar intel_report JSON file and analyzes all (or filtered) datasets.

    Example:
        datarecipe batch-from-radar ./data/reports/intel_report_2024-01-01.json
        datarecipe batch-from-radar ./report.json --orgs Anthropic,OpenAI --limit 5
        datarecipe batch-from-radar ./report.json --incremental --parallel 3
    """
    import os

    from datarecipe.integrations.radar import RadarIntegration

    console.print(f"\n[bold cyan]{'=' * 60}[/bold cyan]")
    console.print("[bold cyan]  DataRecipe æ‰¹é‡åˆ†æ (Radar é›†æˆ)[/bold cyan]")
    console.print(f"[bold cyan]{'=' * 60}[/bold cyan]\n")

    # Load radar report
    console.print(f"[dim]ğŸ“‚ åŠ è½½ Radar æŠ¥å‘Š: {radar_report}[/dim]")
    try:
        integration = RadarIntegration()
        all_datasets = integration.load_radar_report(radar_report)
        console.print(f"[green]âœ“ åŠ è½½ {len(all_datasets)} ä¸ªæ•°æ®é›†[/green]")
    except Exception as e:
        console.print(f"[red]é”™è¯¯: æ— æ³•åŠ è½½ Radar æŠ¥å‘Š - {e}[/red]")
        return

    # Filter datasets
    org_list = [o.strip() for o in orgs.split(",")] if orgs else None
    cat_list = [c.strip() for c in categories.split(",")] if categories else None

    datasets = integration.filter_datasets(
        orgs=org_list,
        categories=cat_list,
        min_downloads=min_downloads,
        limit=0,  # Apply limit after sorting
    )

    if not datasets:
        console.print("[yellow]âš  æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æ•°æ®é›†[/yellow]")
        return

    # Sort datasets
    if sort_by == "downloads":
        datasets.sort(key=lambda x: x.downloads, reverse=True)
    elif sort_by == "name":
        datasets.sort(key=lambda x: x.id.lower())
    elif sort_by == "category":
        datasets.sort(key=lambda x: (x.category or "zzz", -x.downloads))

    # Incremental mode: skip already analyzed
    skipped_count = 0
    if incremental:
        filtered = []
        for ds in datasets:
            safe_name = ds.id.replace("/", "_").replace("\\", "_")
            summary_path = os.path.join(output_dir, safe_name, "recipe_summary.json")
            if os.path.exists(summary_path):
                skipped_count += 1
            else:
                filtered.append(ds)
        datasets = filtered
        if skipped_count > 0:
            console.print(f"[dim]å¢é‡æ¨¡å¼: è·³è¿‡ {skipped_count} ä¸ªå·²åˆ†ææ•°æ®é›†[/dim]")

    # Apply limit after filtering
    if limit > 0:
        datasets = datasets[:limit]

    if not datasets:
        console.print("[green]âœ“ æ‰€æœ‰æ•°æ®é›†å·²åˆ†æå®Œæˆ[/green]")
        return

    console.print(f"[dim]å¾…åˆ†æ: {len(datasets)} ä¸ªæ•°æ®é›† (æ’åº: {sort_by})[/dim]\n")

    # Show datasets to analyze
    console.print("[bold]å¾…åˆ†ææ•°æ®é›†:[/bold]")
    for i, ds in enumerate(datasets[:10], 1):
        console.print(f"  {i}. {ds.id} ({ds.category}, {ds.downloads:,} downloads)")
    if len(datasets) > 10:
        console.print(f"  ... è¿˜æœ‰ {len(datasets) - 10} ä¸ª")
    console.print("")

    # Save progress file for resume capability
    progress_file = os.path.join(output_dir, ".batch_progress.json")

    # Analyze each dataset
    summaries = []
    success_count = 0
    fail_count = 0

    for i, ds in enumerate(datasets, 1):
        console.print(f"\n[bold]â”â”â” [{i}/{len(datasets)}] {ds.id} â”â”â”[/bold]")

        try:
            # Import here to avoid circular imports
            from datasets import load_dataset

            from datarecipe.extractors import PromptExtractor, RubricsAnalyzer
            from datarecipe.generators import HumanMachineSplitter, TaskType

            # Create output directory
            safe_name = ds.id.replace("/", "_").replace("\\", "_")
            dataset_output_dir = os.path.join(output_dir, safe_name)
            os.makedirs(dataset_output_dir, exist_ok=True)

            # Load dataset
            console.print("[dim]  ğŸ“¥ åŠ è½½æ•°æ®...[/dim]")
            try:
                dataset = load_dataset(ds.id, split="train", streaming=True)
            except ValueError:
                # Try test split
                try:
                    dataset = load_dataset(ds.id, split="test", streaming=True)
                except Exception:
                    raise ValueError("æ— æ³•æ‰¾åˆ°å¯ç”¨çš„ split")

            # Collect samples
            schema_info = {}
            sample_items = []
            rubrics = []
            messages = []

            for j, item in enumerate(dataset):
                if j >= sample_size:
                    break

                # Schema info
                if j < 5:
                    for field, value in item.items():
                        if field not in schema_info:
                            schema_info[field] = {"type": type(value).__name__, "nested_type": None}
                    sample_items.append(item)

                # Collect rubrics/messages
                for field in ["rubrics", "rubric", "criteria"]:
                    if field in item:
                        v = item[field]
                        if isinstance(v, list):
                            rubrics.extend(v)
                        elif isinstance(v, str):
                            rubrics.append(v)

                if "messages" in item:
                    messages.extend(item.get("messages", []))

            sample_count = j + 1
            console.print(f"[dim]  âœ“ åŠ è½½ {sample_count} æ ·æœ¬[/dim]")

            # Detect dataset type
            is_preference = "chosen" in schema_info and "rejected" in schema_info
            is_swe = "repo" in schema_info and "patch" in schema_info

            dataset_type = ds.category or ""
            if is_preference:
                dataset_type = "preference"
            elif is_swe:
                dataset_type = "swe_bench"
            elif rubrics:
                dataset_type = "evaluation"

            # Human-machine allocation
            console.print("[dim]  âš™ï¸ è®¡ç®—æˆæœ¬...[/dim]")
            splitter = HumanMachineSplitter(region=region)
            allocation = splitter.analyze(
                dataset_size=sample_count,
                task_types=[
                    TaskType.CONTEXT_CREATION,
                    TaskType.TASK_DESIGN,
                    TaskType.RUBRICS_WRITING,
                    TaskType.DATA_GENERATION,
                    TaskType.QUALITY_REVIEW,
                ],
            )

            # Rubrics analysis
            rubrics_result = None
            if rubrics:
                analyzer = RubricsAnalyzer()
                rubrics_result = analyzer.analyze(rubrics, task_count=sample_count)

            # Prompt analysis
            prompt_library = None
            if messages:
                extractor = PromptExtractor()
                prompt_library = extractor.extract(messages)

            # LLM analysis for unknown types
            llm_analysis = None
            if use_llm and not dataset_type:
                console.print("[dim]  ğŸ¤– LLM åˆ†æä¸­...[/dim]")
                try:
                    from datarecipe.analyzers.llm_dataset_analyzer import LLMDatasetAnalyzer

                    llm_analyzer = LLMDatasetAnalyzer()
                    llm_analysis = llm_analyzer.analyze(
                        dataset_id=ds.id,
                        schema_info=schema_info,
                        sample_items=sample_items,
                        sample_count=sample_count,
                    )
                    dataset_type = llm_analysis.dataset_type
                except Exception as e:
                    console.print(f"[yellow]  âš  LLM åˆ†æå¤±è´¥: {e}[/yellow]")

            # Create summary
            summary = RadarIntegration.create_summary(
                dataset_id=ds.id,
                dataset_type=dataset_type,
                category=ds.category,
                allocation=allocation,
                rubrics_result=rubrics_result,
                prompt_library=prompt_library,
                schema_info=schema_info,
                sample_count=sample_count,
                llm_analysis=llm_analysis,
                output_dir=dataset_output_dir,
            )

            # Save summary
            RadarIntegration.save_summary(summary, dataset_output_dir)
            summaries.append(summary)
            success_count += 1

            console.print(
                f"[green]  âœ“ å®Œæˆ: {dataset_type or 'unknown'}, ${allocation.total_cost:,.0f}[/green]"
            )

            # Update progress file
            progress = {
                "total": len(datasets),
                "completed": success_count,
                "failed": fail_count,
                "last_dataset": ds.id,
                "summaries": [s.dataset_id for s in summaries],
            }
            with open(progress_file, "w", encoding="utf-8") as f:
                json.dump(progress, f, indent=2)

        except Exception as e:
            fail_count += 1
            console.print(f"[red]  âœ— å¤±è´¥: {e}[/red]")

            # Log failed dataset
            failed_log = os.path.join(output_dir, ".batch_failed.log")
            with open(failed_log, "a", encoding="utf-8") as f:
                f.write(f"{ds.id}: {e}\n")
            continue

    # Clean up progress file on completion
    if os.path.exists(progress_file):
        os.remove(progress_file)

    # Generate aggregated report
    console.print(f"\n[bold cyan]{'=' * 60}[/bold cyan]")
    console.print("[bold cyan]  æ‰¹é‡åˆ†æå®Œæˆ[/bold cyan]")
    console.print(f"[bold cyan]{'=' * 60}[/bold cyan]\n")

    console.print(f"æˆåŠŸ: [green]{success_count}[/green]")
    console.print(f"å¤±è´¥: [red]{fail_count}[/red]")
    if skipped_count > 0:
        console.print(f"è·³è¿‡: [dim]{skipped_count}[/dim] (å·²åˆ†æ)")

    if summaries:
        # Save aggregated summary
        aggregate = RadarIntegration.aggregate_summaries(summaries)
        aggregate_path = os.path.join(output_dir, "batch_summary.json")
        with open(aggregate_path, "w", encoding="utf-8") as f:
            json.dump(aggregate, f, indent=2, ensure_ascii=False)

        console.print("\n[bold]æ±‡æ€»ç»Ÿè®¡:[/bold]")
        console.print(f"  æ€»å¤åˆ»æˆæœ¬: ${aggregate['total_reproduction_cost']['total']:,.0f}")
        console.print(f"  å¹³å‡äººå·¥å æ¯”: {aggregate['avg_human_percentage']:.0f}%")
        console.print(f"  ç±»å‹åˆ†å¸ƒ: {aggregate['type_distribution']}")

        console.print("\n[bold]è¾“å‡ºæ–‡ä»¶:[/bold]")
        console.print(f"  ğŸ“Š æ±‡æ€»æŠ¥å‘Š: [cyan]{aggregate_path}[/cyan]")
        console.print(f"  ğŸ“ å„æ•°æ®é›†: [cyan]{output_dir}/<dataset>/recipe_summary.json[/cyan]")


@click.command("integrate-report")
@click.option("--radar-report", "-r", help="Path to Radar intel report JSON")
@click.option("--output-dir", "-o", default="./reports", help="Output directory")
@click.option("--recipe-dir", default="./projects", help="Recipe analysis directory")
@click.option("--start-date", help="Period start date (YYYY-MM-DD)")
@click.option("--end-date", help="Period end date (YYYY-MM-DD)")
@click.option(
    "--format", "-f", "formats", multiple=True, default=["md", "json"], help="Output formats"
)
def integrate_report(
    radar_report: str,
    output_dir: str,
    recipe_dir: str,
    start_date: str,
    end_date: str,
    formats: tuple,
):
    """
    Generate integrated report combining Radar discoveries and Recipe analysis.

    Example:
        datarecipe integrate-report -r ./intel_report.json -o ./reports
        datarecipe integrate-report --recipe-dir ./projects
    """
    from datarecipe.reports import IntegratedReportGenerator

    console.print("\n[bold cyan]ç”Ÿæˆæ•´åˆæŠ¥å‘Š[/bold cyan]\n")

    generator = IntegratedReportGenerator(
        recipe_output_dir=recipe_dir,
    )

    # Generate report
    report = generator.generate_weekly_report(
        radar_report_path=radar_report,
        start_date=start_date,
        end_date=end_date,
    )

    # Display summary
    console.print(f"å‘¨æœŸ: {report.period_start} ~ {report.period_end}")
    console.print(f"å‘ç°æ•°æ®é›†: {report.total_discovered}")
    console.print(f"å·²åˆ†æ: {report.total_analyzed}")
    console.print(f"æ€»å¤åˆ»æˆæœ¬: ${report.total_reproduction_cost:,.0f}")
    console.print("")

    if report.insights:
        console.print("[bold]æ´å¯Ÿ:[/bold]")
        for insight in report.insights:
            console.print(f"  â€¢ {insight}")
        console.print("")

    # Save report
    paths = generator.save_report(report, output_dir, list(formats))

    console.print("[bold]ç”Ÿæˆæ–‡ä»¶:[/bold]")
    for _fmt, path in paths.items():
        console.print(f"  ğŸ“„ {path}")
