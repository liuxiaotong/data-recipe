"""Specification document analysis command."""

import json
import sys
from pathlib import Path

import click
from rich.console import Console

from datarecipe.cli._helpers import console


@click.command("analyze-spec")
@click.argument("file_path", type=click.Path(exists=True), required=False)
@click.option("--output-dir", "-o", default="./projects", help="Output directory")
@click.option(
    "--size", "-s", default=100, type=int, help="Target dataset size (for cost estimation)"
)
@click.option("--region", "-r", default="china", help="Region for cost calculation (china/us)")
@click.option(
    "--provider",
    "-p",
    default="anthropic",
    type=click.Choice(["anthropic", "openai"]),
    help="LLM provider",
)
@click.option(
    "--interactive",
    "-i",
    is_flag=True,
    help="Interactive mode: output prompt, wait for JSON input from stdin",
)
@click.option(
    "--from-json",
    "from_json",
    type=click.Path(exists=True),
    help="Load analysis from JSON file instead of using LLM",
)
def analyze_spec(
    file_path: str,
    output_dir: str,
    size: int,
    region: str,
    provider: str,
    interactive: bool,
    from_json: str,
):
    """
    Analyze a specification/requirements document and generate project artifacts.

    Supports PDF, Word (docx), images (png/jpg), and text files.
    Uses LLM to extract structured information and generate:
    - Annotation specification
    - Executive summary
    - Milestone plan
    - Cost breakdown
    - Industry benchmark comparison

    Three modes of operation:

    \b
    1. API mode (default): Uses LLM API to analyze document
       datarecipe analyze-spec requirements.pdf

    \b
    2. Interactive mode: For use within Claude Code/Desktop
       datarecipe analyze-spec requirements.pdf --interactive
       (Outputs prompt, waits for JSON on stdin)

    \b
    3. From JSON: Load pre-computed analysis
       datarecipe analyze-spec requirements.pdf --from-json analysis.json
    """
    import os

    from datarecipe.analyzers.spec_analyzer import SpecAnalyzer
    from datarecipe.generators.spec_output import SpecOutputGenerator

    # Validate arguments
    if not file_path and not from_json:
        console.print("[red]é”™è¯¯: éœ€è¦æä¾›æ–‡æ¡£è·¯å¾„æˆ– --from-json å‚æ•°[/red]")
        return

    # Display header (to stderr in interactive mode)
    output = console if not interactive else Console(file=sys.stderr)

    output.print(f"\n[bold cyan]{'=' * 60}[/bold cyan]")
    output.print("[bold cyan]  DataRecipe éœ€æ±‚æ–‡æ¡£åˆ†æ[/bold cyan]")
    output.print(f"[bold cyan]{'=' * 60}[/bold cyan]\n")

    if file_path:
        file_name = Path(file_path).name
        output.print(f"æ–‡æ¡£: [bold]{file_name}[/bold]")
    output.print(f"ç›®æ ‡è§„æ¨¡: [bold]{size}[/bold] æ¡")
    output.print(f"åŒºåŸŸ: [bold]{region}[/bold]")

    if interactive:
        output.print("æ¨¡å¼: [bold]äº¤äº’æ¨¡å¼[/bold] (ç­‰å¾… stdin è¾“å…¥)\n")
    elif from_json:
        output.print("æ¨¡å¼: [bold]ä» JSON åŠ è½½[/bold]\n")
    else:
        output.print(f"LLM: [bold]{provider}[/bold]\n")

    try:
        analyzer = SpecAnalyzer(provider=provider)
        analysis = None

        # Mode 1: From JSON file
        if from_json:
            output.print("[dim]ğŸ“„ ä» JSON åŠ è½½åˆ†æç»“æœ...[/dim]")
            with open(from_json, encoding="utf-8") as f:
                extracted = json.load(f)

            # Parse document if provided (for metadata)
            doc = None
            if file_path:
                doc = analyzer.parse_document(file_path)
                if doc.has_images():
                    output.print(f"[green]âœ“ æ–‡æ¡£è§£æå®Œæˆ (åŒ…å« {len(doc.images)} å¼ å›¾ç‰‡)[/green]")
                else:
                    output.print("[green]âœ“ æ–‡æ¡£è§£æå®Œæˆ[/green]")

            analysis = analyzer.create_analysis_from_json(extracted, doc)
            output.print(f"[green]âœ“ åŠ è½½å®Œæˆ: {analysis.project_name or 'æœªå‘½åé¡¹ç›®'}[/green]")

        # Mode 2: Interactive mode
        elif interactive:
            output.print("[dim]ğŸ“„ è§£ææ–‡æ¡£...[/dim]")
            doc = analyzer.parse_document(file_path)

            if doc.has_images():
                output.print(f"[green]âœ“ æ–‡æ¡£è§£æå®Œæˆ (åŒ…å« {len(doc.images)} å¼ å›¾ç‰‡)[/green]")
            else:
                output.print("[green]âœ“ æ–‡æ¡£è§£æå®Œæˆ[/green]")

            # Output prompt to stdout
            prompt = analyzer.get_extraction_prompt(doc)
            output.print("\n[bold yellow]=" * 60 + "[/bold yellow]")
            output.print(
                "[bold yellow]è¯·å°†ä»¥ä¸‹å†…å®¹äº¤ç»™ LLM åˆ†æï¼Œç„¶åè¾“å…¥ JSON ç»“æœï¼š[/bold yellow]"
            )
            output.print("[bold yellow]=" * 60 + "[/bold yellow]\n")

            # Print prompt to stdout (for piping to LLM)
            print(prompt)

            output.print("\n[bold yellow]=" * 60 + "[/bold yellow]")
            output.print("[bold yellow]è¯·è¾“å…¥ LLM è¿”å›çš„ JSON (ä»¥ç©ºè¡Œç»“æŸ)ï¼š[/bold yellow]")
            output.print("[bold yellow]=" * 60 + "[/bold yellow]\n")

            # Read JSON from stdin
            json_lines = []
            try:
                for line in sys.stdin:
                    if line.strip() == "":
                        break
                    json_lines.append(line)
            except EOFError:
                pass

            json_text = "".join(json_lines)
            if not json_text.strip():
                output.print("[red]é”™è¯¯: æœªæ”¶åˆ° JSON è¾“å…¥[/red]")
                return

            # Parse JSON
            try:
                # Try to extract JSON from markdown code block
                import re

                json_match = re.search(r"```json\s*(.*?)\s*```", json_text, re.DOTALL)
                if json_match:
                    json_text = json_match.group(1)
                else:
                    json_match = re.search(r"\{.*\}", json_text, re.DOTALL)
                    if json_match:
                        json_text = json_match.group(0)

                extracted = json.loads(json_text)
                analysis = analyzer.create_analysis_from_json(extracted, doc)
                output.print(
                    f"[green]âœ“ JSON è§£ææˆåŠŸ: {analysis.project_name or 'æœªå‘½åé¡¹ç›®'}[/green]"
                )
            except json.JSONDecodeError as e:
                output.print(f"[red]é”™è¯¯: JSON è§£æå¤±è´¥ - {e}[/red]")
                return

        # Mode 3: API mode (default)
        else:
            output.print("[dim]ğŸ“„ è§£ææ–‡æ¡£...[/dim]")
            analysis = analyzer.analyze(file_path)

            if analysis.has_images:
                output.print(f"[green]âœ“ æ–‡æ¡£è§£æå®Œæˆ (åŒ…å« {analysis.image_count} å¼ å›¾ç‰‡)[/green]")
            else:
                output.print("[green]âœ“ æ–‡æ¡£è§£æå®Œæˆ[/green]")

            output.print("[dim]ğŸ¤– ä½¿ç”¨ LLM æå–ç»“æ„åŒ–ä¿¡æ¯...[/dim]")
            if analysis.project_name:
                output.print(f"[green]âœ“ è¯†åˆ«é¡¹ç›®: {analysis.project_name}[/green]")
                output.print(f"  ç±»å‹: {analysis.dataset_type or 'unknown'}")
                output.print(f"  éš¾åº¦: {analysis.estimated_difficulty or 'unknown'}")
                output.print(f"  äººå·¥å æ¯”: {analysis.estimated_human_percentage:.0f}%")
            else:
                output.print("[yellow]âš  LLM æå–ä¿¡æ¯æœ‰é™ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼[/yellow]")

        # Step 3: LLM Enhancement (optional, enriches document quality)
        enhanced_context = None
        try:
            from datarecipe.generators.llm_enhancer import LLMEnhancer

            enhance_mode = "api" if not interactive else "interactive"
            enhancer = LLMEnhancer(mode=enhance_mode, provider=provider)
            enhanced_context = enhancer.enhance(
                dataset_id=analysis.project_name or "spec_analysis",
                dataset_type=analysis.dataset_type or "unknown",
                domain=analysis.estimated_domain or "é€šç”¨",
                difficulty=analysis.estimated_difficulty or "medium",
                human_percentage=analysis.estimated_human_percentage,
                total_cost=0,
            )
            if enhanced_context and enhanced_context.generated:
                output.print("[green]âœ“ LLM å¢å¼ºå®Œæˆ[/green]")
        except Exception:
            pass

        # Step 4: Generate outputs
        output.print("[dim]ğŸ“ ç”Ÿæˆé¡¹ç›®æ–‡æ¡£...[/dim]")
        generator = SpecOutputGenerator(output_dir=output_dir)
        result = generator.generate(
            analysis=analysis,
            target_size=size,
            region=region,
            enhanced_context=enhanced_context,
        )

        if not result.success:
            output.print(f"[red]é”™è¯¯: {result.error}[/red]")
            return

        output.print("[green]âœ“ ç”Ÿæˆå®Œæˆ[/green]")

        # Display summary
        output.print(f"\n[bold cyan]{'=' * 60}[/bold cyan]")
        output.print("[bold cyan]  åˆ†æå®Œæˆ[/bold cyan]")
        output.print(f"[bold cyan]{'=' * 60}[/bold cyan]\n")

        output.print("[bold]ç”Ÿæˆçš„æ–‡ä»¶:[/bold]")
        for fname in result.files_generated:
            fpath = os.path.join(result.output_dir, fname)
            if os.path.exists(fpath):
                fsize = os.path.getsize(fpath)
                if fsize > 1024:
                    size_str = f"{fsize / 1024:.1f}KB"
                else:
                    size_str = f"{fsize}B"
                icon = "ğŸ“Š" if fname.endswith(".json") else "ğŸ“„" if fname.endswith(".md") else "ğŸ“‘"
                output.print(f"  {icon} {fname} ({size_str})")

        output.print(f"\n[bold]è¾“å‡ºç›®å½•:[/bold] [cyan]{result.output_dir}[/cyan]")

        # Key files
        output.print("\n[bold]æ ¸å¿ƒäº§å‡º:[/bold]")
        output.print(
            f"  ğŸ“„ æ‰§è¡Œæ‘˜è¦: [cyan]{result.output_dir}/01_å†³ç­–å‚è€ƒ/EXECUTIVE_SUMMARY.md[/cyan]"
        )
        output.print(
            f"  ğŸ“‹ é‡Œç¨‹ç¢‘è®¡åˆ’: [cyan]{result.output_dir}/02_é¡¹ç›®ç®¡ç†/MILESTONE_PLAN.md[/cyan]"
        )
        output.print(
            f"  ğŸ“ æ ‡æ³¨è§„èŒƒ: [cyan]{result.output_dir}/03_æ ‡æ³¨è§„èŒƒ/ANNOTATION_SPEC.md[/cyan]"
        )

    except FileNotFoundError as e:
        output.print(f"[red]é”™è¯¯: æ–‡ä»¶æœªæ‰¾åˆ° - {e}[/red]")
    except ValueError as e:
        output.print(f"[red]é”™è¯¯: {e}[/red]")
    except ImportError as e:
        output.print(f"[red]é”™è¯¯: ç¼ºå°‘ä¾èµ– - {e}[/red]")
        output.print("[dim]è¯·å®‰è£…æ‰€éœ€ä¾èµ–: pip install anthropic pymupdf python-docx[/dim]")
    except Exception as e:
        output.print(f"[red]é”™è¯¯: {e}[/red]")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    analyze_spec()
