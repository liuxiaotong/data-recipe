"""Deep analysis command and report generators."""

import json

import click

from datarecipe.cli._helpers import console


@click.command("deep-analyze")
@click.argument("dataset_id")
@click.option("--output-dir", "-o", default="./projects", help="Output directory")
@click.option("--sample-size", "-n", default=500, help="Number of samples to analyze")
@click.option(
    "--size", "-s", default=None, type=int, help="Target dataset size (for cost estimation)"
)
@click.option("--region", "-r", default="china", help="Region for cost calculation")
@click.option("--split", default=None, help="Dataset split (auto-detect if not specified)")
@click.option(
    "--use-llm",
    is_flag=True,
    default=False,
    help="Use LLM for intelligent analysis of unknown dataset types",
)
@click.option(
    "--llm-provider",
    default="anthropic",
    type=click.Choice(["anthropic", "openai"]),
    help="LLM provider for intelligent analysis",
)
@click.option(
    "--enhance-mode",
    default="auto",
    type=click.Choice(["auto", "interactive", "api"]),
    help="LLM enhancement mode: auto (detect), interactive (Claude Code/App), api (standalone)",
)
@click.option("--force", "-f", is_flag=True, help="Force re-analysis, ignore cache")
@click.option("--no-cache", is_flag=True, help="Don't use or update cache")
def deep_analyze(
    dataset_id: str,
    output_dir: str,
    sample_size: int,
    size: int,
    region: str,
    split: str,
    use_llm: bool,
    llm_provider: str,
    enhance_mode: str,
    force: bool,
    no_cache: bool,
):
    """
    Run comprehensive deep analysis on a dataset.

    Generates both JSON data files and a human-readable Markdown report.
    Supports HuggingFace dataset IDs and local files (CSV, Parquet, JSONL).

    Examples:
        datarecipe deep-analyze tencent/CL-bench -o ./output
        datarecipe deep-analyze ./data/train.csv -n 100
        datarecipe deep-analyze ./data/train.jsonl
    """
    import os

    from datarecipe.cache import AnalysisCache
    from datarecipe.core.deep_analyzer import DeepAnalyzerCore

    # Create output directory with dataset subdirectory
    safe_dataset_name = dataset_id.replace("/", "_").replace("\\", "_").replace(":", "_")
    dataset_output_dir = os.path.join(output_dir, safe_dataset_name)

    # Check cache first (unless --force or --no-cache)
    cache = AnalysisCache() if not no_cache else None
    if cache and not force:
        cached = cache.get(dataset_id, check_freshness=True)
        if cached:
            console.print(f"\n[bold cyan]{'=' * 60}[/bold cyan]")
            console.print("[bold cyan]  DataRecipe æ·±åº¦é€†å‘åˆ†æ (ç¼“å­˜å‘½ä¸­)[/bold cyan]")
            console.print(f"[bold cyan]{'=' * 60}[/bold cyan]\n")
            console.print(f"æ•°æ®é›†: [bold]{dataset_id}[/bold]")
            console.print(f"[green]âœ“ ä½¿ç”¨ç¼“å­˜ç»“æœ (åˆ›å»ºäº {cached.created_at[:10]})[/green]")
            console.print(f"  ç±»å‹: {cached.dataset_type or 'unknown'}")
            console.print(f"  æ ·æœ¬: {cached.sample_count}")

            if cached.output_dir != dataset_output_dir:
                os.makedirs(dataset_output_dir, exist_ok=True)
                cache.copy_to_output(dataset_id, dataset_output_dir)
                console.print(f"  è¾“å‡º: {dataset_output_dir}")
            else:
                console.print(f"  è¾“å‡º: {cached.output_dir}")

            console.print("\n[dim]ä½¿ç”¨ --force å¼ºåˆ¶é‡æ–°åˆ†æ[/dim]")
            return

    # Display header
    console.print(f"\n[bold cyan]{'=' * 60}[/bold cyan]")
    console.print("[bold cyan]  DataRecipe æ·±åº¦é€†å‘åˆ†æ[/bold cyan]")
    console.print(f"[bold cyan]{'=' * 60}[/bold cyan]\n")
    console.print(f"æ•°æ®é›†: [bold]{dataset_id}[/bold]")
    console.print(f"è¾“å‡ºç›®å½•: [bold]{dataset_output_dir}[/bold]\n")

    try:
        # Use shared DeepAnalyzerCore
        analyzer = DeepAnalyzerCore(
            output_dir=output_dir,
            region=region,
            use_llm=use_llm,
            llm_provider=llm_provider,
            enhance_mode=enhance_mode,
        )

        console.print("[dim]ğŸ“¥ åŠ è½½æ•°æ®é›†...[/dim]")
        result = analyzer.analyze(
            dataset_id=dataset_id,
            sample_size=sample_size,
            split=split,
            target_size=size,
        )

        if not result.success:
            console.print(f"[red]é”™è¯¯: {result.error}[/red]")
            return

        console.print(f"[green]âœ“ åŠ è½½å®Œæˆ: {result.sample_count} æ ·æœ¬[/green]")

        # Display analysis results
        if result.dataset_type == "preference":
            console.print("\n[dim]ğŸ”„ åˆ†æåå¥½æ¨¡å¼...[/dim]")
            console.print(f"[green]âœ“ åå¥½åˆ†æ: {result.sample_count} å¯¹[/green]")
        elif result.dataset_type == "swe_bench":
            console.print("\n[dim]ğŸ”§ åˆ†æ SWE ä»»åŠ¡...[/dim]")
            console.print("[green]âœ“ SWE åˆ†æå®Œæˆ[/green]")
        elif result.rubric_patterns > 0:
            console.print("\n[dim]ğŸ“Š åˆ†æè¯„åˆ†æ ‡å‡†...[/dim]")
            console.print(f"[green]âœ“ è¯„åˆ†æ ‡å‡†: {result.rubric_patterns} ç§æ¨¡å¼[/green]")

        if result.prompt_templates > 0:
            console.print("[dim]ğŸ“ æå– Prompt æ¨¡æ¿...[/dim]")
            console.print(f"[green]âœ“ Promptæ¨¡æ¿: {result.prompt_templates} ä¸ª[/green]")

        console.print("[dim]âš™ï¸ è®¡ç®—äººæœºåˆ†é…...[/dim]")
        console.print(
            f"[green]âœ“ äººæœºåˆ†é…: äººå·¥ {result.human_percentage:.0f}%, æœºå™¨ {100 - result.human_percentage:.0f}%[/green]"
        )

        console.print("\n[dim]ğŸ“„ ç”Ÿæˆç»¼åˆæŠ¥å‘Š...[/dim]")
        console.print("[green]âœ“ ç»¼åˆæŠ¥å‘Šå·²ä¿å­˜[/green]")
        console.print("[dim]ğŸ“‹ ç”Ÿæˆå¤åˆ»æŒ‡å—...[/dim]")
        console.print("[green]âœ“ å¤åˆ»æŒ‡å—å·²ä¿å­˜[/green]")
        console.print("[dim]ğŸ“¦ ç”Ÿæˆæ ‡å‡†åŒ–æ‘˜è¦...[/dim]")
        console.print("[green]âœ“ æ ‡å‡†åŒ–æ‘˜è¦å·²ä¿å­˜ (Radar å…¼å®¹)[/green]")
        console.print("[dim]ğŸ“š æ›´æ–°çŸ¥è¯†åº“...[/dim]")
        console.print("[green]âœ“ çŸ¥è¯†åº“å·²æ›´æ–°[/green]")
        console.print("[dim]ğŸ’¾ æ›´æ–°ç¼“å­˜...[/dim]")
        console.print("[green]âœ“ ç¼“å­˜å·²æ›´æ–°[/green]")

        # Display summary
        console.print(f"\n[bold cyan]{'=' * 60}[/bold cyan]")
        console.print("[bold cyan]  åˆ†æå®Œæˆ[/bold cyan]")
        console.print(f"[bold cyan]{'=' * 60}[/bold cyan]\n")

        console.print("[bold]ç”Ÿæˆçš„æ–‡ä»¶:[/bold]")
        for fname in result.files_generated:
            fpath = os.path.join(result.output_dir, fname)
            if os.path.exists(fpath):
                fsize = os.path.getsize(fpath)
                if fsize > 1024:
                    size_str = f"{fsize / 1024:.1f}KB"
                else:
                    size_str = f"{fsize}B"
                icon = "ğŸ“Š" if fname.endswith(".json") else "ğŸ“„" if fname.endswith(".md") else "ğŸ“‘"
                console.print(f"  {icon} {fname} ({size_str})")

        report_path = os.path.join(result.output_dir, "ANALYSIS_REPORT.md")
        guide_path = os.path.join(result.output_dir, "REPRODUCTION_GUIDE.md")
        console.print("\n[bold]æ ¸å¿ƒäº§å‡º:[/bold]")
        console.print(f"  ğŸ“„ åˆ†ææŠ¥å‘Š: [cyan]{report_path}[/cyan]")
        console.print(f"  ğŸ“‹ å¤åˆ»æŒ‡å—: [cyan]{guide_path}[/cyan]")

        # Display warnings if any
        if hasattr(result, "warnings") and result.warnings:
            console.print(f"\n[yellow]âš  éƒ¨åˆ†æ­¥éª¤è·³è¿‡ ({len(result.warnings)} é¡¹):[/yellow]")
            for w in result.warnings:
                console.print(f"  [dim]Â· {w}[/dim]")

    except Exception as e:
        console.print(f"[red]é”™è¯¯: {e}[/red]")
        import traceback

        traceback.print_exc()


def _generate_analysis_report(
    dataset_id: str,
    sample_count: int,
    actual_size: int,
    rubrics_result,
    prompt_library,
    strategy_result,
    allocation,
    region: str,
) -> str:
    """Generate a comprehensive Markdown analysis report."""
    from datetime import datetime

    lines = []
    lines.append(f"# ğŸ”¬ {dataset_id} æ·±åº¦é€†å‘åˆ†ææŠ¥å‘Š")
    lines.append("")
    lines.append(f"> **åˆ†ææ—¥æœŸ**: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    lines.append(f"> **æ•°æ®é›†**: {dataset_id}")
    lines.append(f"> **åˆ†ææ ·æœ¬**: {sample_count} æ¡")
    lines.append(f"> **ç›®æ ‡è§„æ¨¡**: {actual_size:,} æ¡")
    lines.append("")
    lines.append("---")
    lines.append("")

    # Executive Summary
    lines.append("## ğŸ“Š æ‰§è¡Œæ‘˜è¦")
    lines.append("")
    lines.append("| ç»´åº¦ | å‘ç° |")
    lines.append("|------|------|")

    if rubrics_result:
        lines.append(
            f"| **è¯„åˆ†æ ‡å‡†** | {rubrics_result.total_rubrics:,} æ¡ï¼Œ{rubrics_result.unique_patterns:,} ç§ç‹¬ç‰¹æ¨¡å¼ |"
        )
    if prompt_library:
        lines.append(f"| **Promptæ¨¡æ¿** | {prompt_library.unique_count} ä¸ªå»é‡åçš„ç³»ç»Ÿæç¤ºæ¨¡æ¿ |")
    if strategy_result:
        lines.append(
            f"| **æ•°æ®æ¥æº** | æ··åˆç­–ç•¥ï¼ˆåˆæˆ {strategy_result.synthetic_score * 100:.0f}% + æ”¹ç¼– {strategy_result.modified_score * 100:.0f}% + ä¸“ä¸š {strategy_result.niche_score * 100:.0f}%ï¼‰ |"
        )

    lines.append(
        f"| **å¤ç°æˆæœ¬** | çº¦ ${allocation.total_cost:,.0f}ï¼ˆäººå·¥ ${allocation.total_human_cost:,.0f} + API ${allocation.total_machine_cost:,.0f}ï¼‰ |"
    )
    lines.append(
        f"| **äººæœºåˆ†é…** | äººå·¥ {allocation.human_work_percentage:.0f}%ï¼Œæœºå™¨ {allocation.machine_work_percentage:.0f}% |"
    )
    lines.append("")
    lines.append("---")
    lines.append("")

    # Rubrics Analysis
    if rubrics_result:
        lines.append("## 1ï¸âƒ£ è¯„åˆ†æ ‡å‡†ï¼ˆRubricsï¼‰æ¨¡å¼åˆ†æ")
        lines.append("")
        lines.append("### 1.1 æ€»ä½“ç»Ÿè®¡")
        lines.append("")
        lines.append(f"- **æ€»æ•°**: {rubrics_result.total_rubrics:,} æ¡è¯„åˆ†æ ‡å‡†")
        lines.append(f"- **ç‹¬ç‰¹æ¨¡å¼**: {rubrics_result.unique_patterns:,} ç§")
        lines.append(f"- **å¹³å‡æ¯ä»»åŠ¡**: {rubrics_result.avg_rubrics_per_task:.1f} æ¡")
        lines.append("")

        lines.append("### 1.2 é«˜é¢‘åŠ¨è¯åˆ†å¸ƒ")
        lines.append("")
        lines.append("| æ’å | åŠ¨è¯ | å‡ºç°æ¬¡æ•° | å æ¯” |")
        lines.append("|------|------|----------|------|")

        sorted_verbs = sorted(rubrics_result.verb_distribution.items(), key=lambda x: -x[1])[:10]
        for i, (verb, count) in enumerate(sorted_verbs, 1):
            pct = count / rubrics_result.total_rubrics * 100
            lines.append(f"| {i} | **{verb}** | {count:,} | {pct:.1f}% |")
        lines.append("")

        lines.append("### 1.3 è¯„åˆ†ç±»åˆ«åˆ†å¸ƒ")
        lines.append("")
        sorted_cats = sorted(rubrics_result.category_distribution.items(), key=lambda x: -x[1])
        for cat, count in sorted_cats[:5]:
            pct = count / rubrics_result.total_rubrics * 100
            bar_len = int(pct / 2.5)
            bar = "â–ˆ" * bar_len
            lines.append(f"- **{cat}**: {bar} {pct:.1f}% ({count:,})")
        lines.append("")

        if rubrics_result.structured_templates:
            lines.append("### 1.4 æ¨¡æ¿åŒ–ç»“æ„ï¼ˆTop 5ï¼‰")
            lines.append("")
            lines.append("| ç±»åˆ« | åŠ¨ä½œ | ç›®æ ‡ | æ¡ä»¶ | é¢‘æ¬¡ |")
            lines.append("|------|------|------|------|------|")
            for entry in rubrics_result.structured_templates[:5]:
                action = entry.get("action") or "N/A"
                target = entry.get("target") or "N/A"
                condition = entry.get("condition") or "â€”"
                freq = entry.get("frequency", 0)
                lines.append(
                    f"| {entry.get('category', 'general')} | {action} | {target} | {condition} | {freq} |"
                )
            lines.append("")
        lines.append("---")
        lines.append("")

    # Prompt Templates
    if prompt_library:
        lines.append("## 2ï¸âƒ£ ç³»ç»Ÿæç¤ºï¼ˆSystem Promptï¼‰æ¨¡æ¿åˆ†æ")
        lines.append("")
        lines.append("### 2.1 æå–ç»Ÿè®¡")
        lines.append("")
        lines.append(f"- **åŸå§‹æ•°é‡**: {prompt_library.total_extracted} æ¡")
        lines.append(f"- **å»é‡å**: {prompt_library.unique_count} ä¸ªç‹¬ç‰¹æ¨¡æ¿")
        lines.append(f"- **å»é‡ç‡**: {prompt_library.deduplication_ratio:.1%}")
        lines.append(f"- **å¹³å‡é•¿åº¦**: {prompt_library.avg_length:,.0f} å­—ç¬¦")
        lines.append("")

        lines.append("### 2.2 æ¨¡æ¿åˆ†ç±»")
        lines.append("")
        lines.append("| ç±»åˆ« | æ•°é‡ | è¯´æ˜ |")
        lines.append("|------|------|------|")
        category_desc = {
            "system": "ç³»ç»Ÿè§’è‰²è®¾å®š",
            "constraint": "çº¦æŸæ¡ä»¶",
            "task": "ä»»åŠ¡è¯´æ˜",
            "format": "æ ¼å¼è¦æ±‚",
            "example": "ç¤ºä¾‹è¯´æ˜",
            "other": "å…¶ä»–ç±»å‹",
        }
        for cat, count in sorted(prompt_library.category_counts.items(), key=lambda x: -x[1]):
            desc = category_desc.get(cat, cat)
            lines.append(f"| **{cat}** | {count} | {desc} |")
        lines.append("")

        if prompt_library.domain_counts:
            lines.append("### 2.3 é¢†åŸŸåˆ†å¸ƒ")
            lines.append("")
            for domain, count in sorted(prompt_library.domain_counts.items(), key=lambda x: -x[1])[
                :5
            ]:
                pct = count / prompt_library.unique_count * 100
                lines.append(f"- **{domain}**: {count} ({pct:.0f}%)")
            lines.append("")
        lines.append("---")
        lines.append("")

    # Context Strategy
    if strategy_result:
        lines.append("## 3ï¸âƒ£ ä¸Šä¸‹æ–‡æ„é€ ç­–ç•¥åˆ†æ")
        lines.append("")
        lines.append("### 3.1 ç­–ç•¥è¯†åˆ«")
        lines.append("")
        lines.append(f"**ä¸»è¦ç­–ç•¥**: {strategy_result.primary_strategy.value}")
        lines.append(f"**ç½®ä¿¡åº¦**: {strategy_result.confidence:.1%}")
        lines.append("")

        lines.append("### 3.2 ç­–ç•¥å¾—åˆ†")
        lines.append("")
        lines.append("| ç­–ç•¥ | å¾—åˆ† | è¯´æ˜ |")
        lines.append("|------|------|------|")
        lines.append(
            f"| ğŸ”§ åˆæˆç”Ÿæˆ | {strategy_result.synthetic_score * 100:.1f}% | ä½¿ç”¨ AI æ¨¡å‹ç”Ÿæˆè™šæ„å†…å®¹ |"
        )
        lines.append(
            f"| ğŸ“ æ”¹ç¼–ä¿®æ”¹ | {strategy_result.modified_score * 100:.1f}% | åŸºäºçœŸå®æ¥æºæ”¹ç¼– |"
        )
        lines.append(
            f"| ğŸ”¬ ä¸“ä¸šé¢†åŸŸ | {strategy_result.niche_score * 100:.1f}% | ä¸“ä¸š/å°ä¼—é¢†åŸŸå†…å®¹ |"
        )
        lines.append("")

        lines.append("### 3.3 æ£€æµ‹åˆ°çš„æŒ‡æ ‡")
        lines.append("")
        if strategy_result.synthetic_indicators:
            lines.append("**ğŸ”§ åˆæˆç”Ÿæˆ**")
            for ind in strategy_result.synthetic_indicators[:5]:
                lines.append(f"- `{ind}`")
            lines.append("")
        if strategy_result.modified_indicators:
            lines.append("**ğŸ“ æ”¹ç¼–ä¿®æ”¹**")
            for ind in strategy_result.modified_indicators[:5]:
                lines.append(f"- `{ind}`")
            lines.append("")
        if strategy_result.niche_indicators:
            lines.append("**ğŸ”¬ ä¸“ä¸šé¢†åŸŸ**")
            for ind in strategy_result.niche_indicators[:5]:
                lines.append(f"- `{ind}`")
            lines.append("")

        if strategy_result.recommendations:
            lines.append("### 3.4 å¤ç°å»ºè®®")
            lines.append("")
            for rec in strategy_result.recommendations:
                lines.append(f"- {rec}")
            lines.append("")
        lines.append("---")
        lines.append("")

    # Human-Machine Allocation
    lines.append("## 4ï¸âƒ£ äººæœºä»»åŠ¡åˆ†é…")
    lines.append("")
    lines.append("### 4.1 åˆ†é…æ€»è§ˆ")
    lines.append("")
    human_pct = allocation.human_work_percentage
    machine_pct = allocation.machine_work_percentage
    human_bar = "â–ˆ" * int(human_pct / 2.5)
    machine_bar = "â–ˆ" * int(machine_pct / 2.5)
    lines.append(f"- äººå·¥å·¥ä½œ: {human_bar} **{human_pct:.0f}%**")
    lines.append(f"- æœºå™¨å·¥ä½œ: {machine_bar} **{machine_pct:.0f}%**")
    lines.append("")

    lines.append("### 4.2 ä»»åŠ¡æ˜ç»†")
    lines.append("")
    lines.append("| ä»»åŠ¡ | åˆ†é…æ–¹å¼ | äººå·¥å æ¯” | äººå·¥æ—¶é•¿ | äººå·¥æˆæœ¬ | æœºå™¨æˆæœ¬ |")
    lines.append("|------|----------|----------|----------|----------|----------|")

    decision_zh = {
        "human_only": "çº¯äººå·¥",
        "machine_only": "çº¯æœºå™¨",
        "human_primary": "äººå·¥ä¸ºä¸»",
        "machine_primary": "æœºå™¨ä¸ºä¸»",
        "balanced": "å‡è¡¡",
    }
    for task in allocation.tasks:
        dec = decision_zh.get(task.decision.value, task.decision.value)
        lines.append(
            f"| **{task.task_name}** | {dec} | {task.human_percentage:.0f}% | {task.human_hours:.1f}h | ${task.human_cost:,.0f} | ${task.machine_cost:.1f} |"
        )
    lines.append("")

    lines.append("### 4.3 æˆæœ¬ä¼°ç®—")
    lines.append("")
    lines.append("| é¡¹ç›® | é‡‘é¢ |")
    lines.append("|------|------|")
    lines.append(f"| äººå·¥æˆæœ¬ | ${allocation.total_human_cost:,.0f} |")
    lines.append(f"| API/æœºå™¨æˆæœ¬ | ${allocation.total_machine_cost:,.0f} |")
    lines.append(f"| **æ€»è®¡** | **${allocation.total_cost:,.0f}** |")
    lines.append(f"| é¢„ä¼°èŠ‚çœ | ${allocation.estimated_savings_vs_all_human:,.0f}ï¼ˆç›¸æ¯”å…¨äººå·¥ï¼‰ |")
    lines.append("")
    lines.append("---")
    lines.append("")

    # Recommendations
    lines.append("## 5ï¸âƒ£ å¤ç°å»ºè®®")
    lines.append("")
    lines.append("### 5.1 å›¢é˜Ÿé…ç½®")
    lines.append("")
    lines.append("| è§’è‰² | äººæ•° | èŒè´£ |")
    lines.append("|------|------|------|")
    lines.append("| é¢†åŸŸä¸“å®¶ | 4 | åˆ›å»ºå’Œå®¡æ ¸ä¸Šä¸‹æ–‡å†…å®¹ |")
    lines.append("| ä»»åŠ¡è®¾è®¡å¸ˆ | 2 | è®¾è®¡è¯„ä¼°ä»»åŠ¡å’Œé—®é¢˜ |")
    lines.append("| æ ‡æ³¨å‘˜ | 4 | ç¼–å†™è¯„åˆ†æ ‡å‡†å’Œæ ‡æ³¨ |")
    lines.append("| QAå®¡æ ¸å‘˜ | 2 | è´¨é‡ä¿è¯å’ŒéªŒè¯ |")
    lines.append("| é¡¹ç›®ç»ç† | 1 | åè°ƒå›¢é˜Ÿå’Œè¿›åº¦è·Ÿè¸ª |")
    lines.append("")

    lines.append("### 5.2 è´¨é‡æ£€æŸ¥ç‚¹")
    lines.append("")
    lines.append("- [ ] ä¸Šä¸‹æ–‡å†…å®¹æ˜¯åŸåˆ›çš„ï¼ˆä¸åœ¨è®­ç»ƒæ•°æ®ä¸­ï¼‰")
    lines.append("- [ ] ä»»åŠ¡éœ€è¦ä¸Šä¸‹æ–‡æ‰èƒ½å›ç­”")
    lines.append("- [ ] è¯„åˆ†æ ‡å‡†éµå¾ªå·²å‘ç°çš„æ¨¡å¼")
    lines.append("- [ ] é€šè¿‡äº¤å‰éªŒè¯å®¡æ ¸")
    lines.append("")
    lines.append("---")
    lines.append("")
    lines.append("> æŠ¥å‘Šç”± DataRecipe è‡ªåŠ¨ç”Ÿæˆ")

    return "\n".join(lines)


def _generate_reproduction_guide(
    dataset_id: str,
    schema_info: dict,
    category_set: set,
    sub_category_set: set,
    system_prompts_by_domain: dict,
    rubrics_examples: list,
    sample_items: list,
    rubrics_result,
    prompt_library,
    allocation,
    # RLHF preference dataset support
    is_preference_dataset: bool = False,
    preference_pairs: list = None,
    preference_topics: dict = None,
    preference_patterns: dict = None,
    # SWE-bench dataset support
    is_swe_dataset: bool = False,
    swe_stats: dict = None,
    # LLM analysis for unknown types
    llm_analysis=None,
) -> str:
    """Generate a practical reproduction guide for recreating a similar dataset."""

    from datarecipe.analyzers.llm_dataset_analyzer import generate_llm_guide_section

    preference_pairs = preference_pairs or []
    preference_topics = preference_topics or {}
    preference_patterns = preference_patterns or {}
    swe_stats = swe_stats or {}

    lines = []
    lines.append(f"# ğŸ“‹ {dataset_id} å¤åˆ»æŒ‡å—")
    lines.append("")

    if is_swe_dataset:
        lines.append(
            "> **è¿™æ˜¯ä¸€ä¸ªè½¯ä»¶å·¥ç¨‹è¯„æµ‹æ•°æ®é›† (SWE-bench é£æ ¼)ã€‚æœ¬æŒ‡å—æä¾›ä»»åŠ¡æ„å»ºè§„èŒƒï¼Œå¸®åŠ©ä½ æ„å»ºç±»ä¼¼çš„ä»£ç ä¿®å¤/åŠŸèƒ½å®ç°è¯„æµ‹é›†ã€‚**"
        )
    elif is_preference_dataset:
        lines.append(
            "> **è¿™æ˜¯ä¸€ä¸ª RLHF åå¥½æ•°æ®é›†ã€‚æœ¬æŒ‡å—æä¾›åå¥½æ ‡æ³¨è§„èŒƒï¼Œå¸®åŠ©ä½ æ„å»ºç±»ä¼¼çš„äººç±»åå¥½æ•°æ®ã€‚**"
        )
    elif llm_analysis and llm_analysis.dataset_type != "unknown":
        lines.append(f"> **æ•°æ®é›†ç±»å‹: {llm_analysis.dataset_type}ã€‚{llm_analysis.purpose}**")
    else:
        lines.append("> **æœ¬æŒ‡å—æä¾›å¯ç›´æ¥æ“ä½œçš„æ¨¡æ¿å’Œè§„èŒƒï¼Œå¸®åŠ©ä½ ä»é›¶å¼€å§‹æ„å»ºç±»ä¼¼é£æ ¼çš„æ•°æ®é›†ã€‚**")
    lines.append("")
    lines.append("---")
    lines.append("")

    # ==================== LLM Analysis Section (if available) ====================
    if llm_analysis and llm_analysis.dataset_type != "unknown":
        lines.append(generate_llm_guide_section(llm_analysis))
        lines.append("")

    # ==================== Section 1: Data Schema ====================
    lines.append("## 1ï¸âƒ£ æ•°æ®ç»“æ„è§„èŒƒ (Schema)")
    lines.append("")
    lines.append("### 1.1 å­—æ®µå®šä¹‰")
    lines.append("")
    lines.append("| å­—æ®µå | ç±»å‹ | å­ç±»å‹ | è¯´æ˜ |")
    lines.append("|--------|------|--------|------|")

    field_descriptions = {
        "messages": "å¯¹è¯æ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å« system/user/assistant è§’è‰²",
        "rubrics": "è¯„åˆ†æ ‡å‡†åˆ—è¡¨ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹å›ç­”è´¨é‡",
        "metadata": "å…ƒæ•°æ®å­—å…¸ï¼ŒåŒ…å«ä»»åŠ¡åˆ†ç±»ç­‰ä¿¡æ¯",
        "input": "ç”¨æˆ·è¾“å…¥/ä¸Šä¸‹æ–‡",
        "output": "æœŸæœ›çš„æ¨¡å‹è¾“å‡º",
        "instruction": "ä»»åŠ¡æŒ‡ä»¤",
        "context": "ä¸Šä¸‹æ–‡ä¿¡æ¯",
        "question": "é—®é¢˜å†…å®¹",
        "answer": "å‚è€ƒç­”æ¡ˆ",
    }

    for field, info in schema_info.items():
        ftype = info["type"]
        nested = info.get("nested_type", "")
        if isinstance(nested, list):
            nested = f"keys: {', '.join(nested[:3])}"
        desc = field_descriptions.get(field, "â€”")
        lines.append(f"| `{field}` | `{ftype}` | `{nested or 'â€”'}` | {desc} |")
    lines.append("")

    # JSON Schema
    lines.append("### 1.2 JSON Schema")
    lines.append("")
    lines.append("```json")
    lines.append("{")
    for i, (field, info) in enumerate(schema_info.items()):
        comma = "," if i < len(schema_info) - 1 else ""
        if info["type"] == "list":
            if info.get("nested_type") == "dict":
                lines.append(f'  "{field}": [{{...}}]{comma}')
            elif info.get("nested_type") == "str":
                lines.append(f'  "{field}": ["..."]' + comma)
            else:
                lines.append(f'  "{field}": []{comma}')
        elif info["type"] == "dict":
            lines.append(f'  "{field}": {{...}}{comma}')
        elif info["type"] == "str":
            lines.append(f'  "{field}": "..."{comma}')
        else:
            lines.append(f'  "{field}": ...{comma}')
    lines.append("}")
    lines.append("```")
    lines.append("")

    # ==================== Section 2: Category System ====================
    lines.append("## 2ï¸âƒ£ ä»»åŠ¡åˆ†ç±»ä½“ç³»")
    lines.append("")

    if category_set:
        lines.append("### 2.1 ä¸»åˆ†ç±» (context_category)")
        lines.append("")
        for cat in sorted(category_set):
            lines.append(f"- `{cat}`")
        lines.append("")

    if sub_category_set:
        lines.append("### 2.2 å­åˆ†ç±» (sub_category)")
        lines.append("")
        for sub in sorted(sub_category_set):
            lines.append(f"- `{sub}`")
        lines.append("")

    if not category_set and not sub_category_set and not is_preference_dataset:
        lines.append("æœªæ£€æµ‹åˆ°åˆ†ç±»ä½“ç³»")
        lines.append("")

    # For preference datasets, show topic distribution
    if is_preference_dataset and preference_topics:
        lines.append("### è¯é¢˜åˆ†å¸ƒ")
        lines.append("")
        lines.append("| è¯é¢˜ | æ•°é‡ | å æ¯” |")
        lines.append("|------|------|------|")
        total = sum(preference_topics.values())
        for topic, count in sorted(preference_topics.items(), key=lambda x: -x[1]):
            pct = count / total * 100 if total > 0 else 0
            lines.append(f"| {topic} | {count} | {pct:.1f}% |")
        lines.append("")

    lines.append("---")
    lines.append("")

    # ==================== Section 2.5: Preference Dataset Guide (if applicable) ====================
    if is_preference_dataset:
        lines.append("## ğŸ”„ åå¥½æ•°æ®é›†ä¸“ç”¨æŒ‡å—")
        lines.append("")
        lines.append("è¿™æ˜¯ä¸€ä¸ª RLHF (Reinforcement Learning from Human Feedback) åå¥½æ•°æ®é›†ã€‚")
        lines.append(
            "æ¯æ¡æ•°æ®åŒ…å«ä¸€å¯¹å›å¤ï¼š`chosen`ï¼ˆè¢«é€‰ä¸­çš„æ›´å¥½å›å¤ï¼‰å’Œ `rejected`ï¼ˆè¢«æ‹’ç»çš„è¾ƒå·®å›å¤ï¼‰ã€‚"
        )
        lines.append("")

        # Preference patterns analysis
        lines.append("### åå¥½æ¨¡å¼åˆ†æ")
        lines.append("")
        if preference_patterns:
            total_patterns = sum(preference_patterns.values())
            if total_patterns > 0:
                lines.append("| æ¨¡å¼ | æ•°é‡ | å æ¯” | è¯´æ˜ |")
                lines.append("|------|------|------|------|")
                pattern_desc = {
                    "chosen_longer": "è¢«é€‰ä¸­å›å¤æ›´é•¿",
                    "rejected_longer": "è¢«æ‹’ç»å›å¤æ›´é•¿",
                    "same_length": "é•¿åº¦ç›¸è¿‘",
                    "chosen_safer": "è¢«é€‰ä¸­å›å¤æ›´å®‰å…¨ï¼ˆrejected å«æ‹’ç»è¯ï¼‰",
                }
                for pattern, count in sorted(preference_patterns.items(), key=lambda x: -x[1]):
                    if count > 0:
                        pct = count / total_patterns * 100
                        desc = pattern_desc.get(pattern, pattern)
                        lines.append(f"| {pattern} | {count} | {pct:.1f}% | {desc} |")
                lines.append("")

        # Preference labeling guidelines
        lines.append("### åå¥½æ ‡æ³¨è§„èŒƒ")
        lines.append("")
        lines.append("æ ‡æ³¨å‘˜éœ€è¦æ¯”è¾ƒä¸¤ä¸ªå›å¤ï¼Œé€‰æ‹©ã€Œæ›´å¥½ã€çš„é‚£ä¸ªã€‚åˆ¤æ–­æ ‡å‡†ï¼š")
        lines.append("")
        lines.append("| ç»´åº¦ | é€‰æ‹© chosen çš„æ¡ä»¶ |")
        lines.append("|------|-------------------|")
        lines.append("| **æœ‰ç”¨æ€§** | æ›´ç›´æ¥åœ°å›ç­”äº†é—®é¢˜ï¼Œæä¾›äº†æ›´å®ç”¨çš„ä¿¡æ¯ |")
        lines.append("| **å‡†ç¡®æ€§** | ä¿¡æ¯æ›´å‡†ç¡®ï¼Œæ²¡æœ‰äº‹å®é”™è¯¯ |")
        lines.append("| **å®‰å…¨æ€§** | ä¸åŒ…å«æœ‰å®³ã€è¿æ³•ã€æ­§è§†æ€§å†…å®¹ |")
        lines.append("| **å®Œæ•´æ€§** | è¦†ç›–äº†é—®é¢˜çš„å„ä¸ªæ–¹é¢ï¼Œä¸é—æ¼å…³é”®ä¿¡æ¯ |")
        lines.append("| **æ¸…æ™°åº¦** | è¡¨è¾¾æ›´æ¸…æ™°ï¼Œç»“æ„æ›´å¥½ï¼Œæ˜“äºç†è§£ |")
        lines.append("| **è¯šå®æ€§** | æ‰¿è®¤ä¸ç¡®å®šæ€§ï¼Œä¸ç¼–é€ ä¿¡æ¯ |")
        lines.append("")

        # Preference pair examples
        if preference_pairs:
            lines.append("### åå¥½å¯¹ç¤ºä¾‹")
            lines.append("")
            for i, pair in enumerate(preference_pairs[:3], 1):
                lines.append(f"**ç¤ºä¾‹ {i}** (è¯é¢˜: `{pair.get('topic', 'unknown')}`)")
                lines.append("")
                lines.append("**Human:**")
                lines.append("```")
                lines.append(pair.get("human_query", "")[:300] or "(æ— )")
                lines.append("```")
                lines.append("")
                lines.append("**Chosen (è¢«é€‰ä¸­):**")
                lines.append("```")
                chosen_resp = pair.get("chosen_response", "")[:400]
                lines.append(chosen_resp if chosen_resp else "(æ— )")
                lines.append("```")
                lines.append("")
                lines.append("**Rejected (è¢«æ‹’ç»):**")
                lines.append("```")
                rejected_resp = pair.get("rejected_response", "")[:400]
                lines.append(rejected_resp if rejected_resp else "(æ— )")
                lines.append("```")
                lines.append("")

        # SOP for preference dataset
        lines.append("### åå¥½æ•°æ®ç”Ÿäº§ SOP")
        lines.append("")
        lines.append("```")
        lines.append("Phase 1: å‡†å¤‡é˜¶æ®µ")
        lines.append("â”œâ”€ æ­¥éª¤ 1.1: æ”¶é›†ç”¨æˆ·é—®é¢˜ï¼ˆå¤šæ ·åŒ–è¯é¢˜ï¼‰")
        lines.append("â”œâ”€ æ­¥éª¤ 1.2: ä½¿ç”¨ LLM ç”Ÿæˆå¤šä¸ªå€™é€‰å›å¤ï¼ˆé€šå¸¸ 2-4 ä¸ªï¼‰")
        lines.append("â””â”€ æ­¥éª¤ 1.3: å‡†å¤‡æ ‡æ³¨ç•Œé¢å’Œæ ‡æ³¨æŒ‡å—")
        lines.append("")
        lines.append("Phase 2: æ ‡æ³¨é˜¶æ®µ")
        lines.append("â”œâ”€ æ­¥éª¤ 2.1: æ ‡æ³¨å‘˜é˜…è¯»é—®é¢˜å’Œæ‰€æœ‰å€™é€‰å›å¤")
        lines.append("â”œâ”€ æ­¥éª¤ 2.2: æ ¹æ®æ ‡æ³¨è§„èŒƒé€‰æ‹©æœ€ä½³å›å¤ (chosen)")
        lines.append("â”œâ”€ æ­¥éª¤ 2.3: é€‰æ‹©æœ€å·®å›å¤ (rejected)")
        lines.append("â””â”€ æ­¥éª¤ 2.4: è®°å½•é€‰æ‹©ç†ç”±ï¼ˆå¯é€‰ï¼Œç”¨äºè´¨æ£€ï¼‰")
        lines.append("")
        lines.append("Phase 3: è´¨é‡æ§åˆ¶")
        lines.append("â”œâ”€ æ­¥éª¤ 3.1: åŒäººæ ‡æ³¨ï¼Œè®¡ç®—ä¸€è‡´æ€§ (Cohen's Kappa)")
        lines.append("â”œâ”€ æ­¥éª¤ 3.2: ä¸ä¸€è‡´æ ·æœ¬ç”±ç¬¬ä¸‰äººä»²è£")
        lines.append("â””â”€ æ­¥éª¤ 3.3: æŠ½æ ·å®¡æ ¸ï¼Œç¡®ä¿æ ‡æ³¨è´¨é‡")
        lines.append("```")
        lines.append("")
        lines.append("---")
        lines.append("")

    # ==================== Section 2.6: SWE-bench Dataset Guide (if applicable) ====================
    if is_swe_dataset and swe_stats:
        lines.append("## ğŸ”§ è½¯ä»¶å·¥ç¨‹è¯„æµ‹æ•°æ®é›†ä¸“ç”¨æŒ‡å—")
        lines.append("")
        lines.append(
            "è¿™æ˜¯ä¸€ä¸ª SWE-bench é£æ ¼çš„è½¯ä»¶å·¥ç¨‹è¯„æµ‹æ•°æ®é›†ï¼Œç”¨äºè¯„ä¼° AI ä»£ç ä¿®å¤å’ŒåŠŸèƒ½å®ç°èƒ½åŠ›ã€‚"
        )
        lines.append("")

        # Language distribution
        if swe_stats.get("languages"):
            lines.append("### ç¼–ç¨‹è¯­è¨€åˆ†å¸ƒ")
            lines.append("")
            lines.append("| è¯­è¨€ | æ•°é‡ | å æ¯” |")
            lines.append("|------|------|------|")
            total = sum(swe_stats["languages"].values())
            for lang, count in sorted(swe_stats["languages"].items(), key=lambda x: -x[1]):
                pct = count / total * 100 if total > 0 else 0
                lines.append(f"| {lang} | {count} | {pct:.1f}% |")
            lines.append("")

        # Repository distribution
        if swe_stats.get("repos"):
            lines.append("### ä»“åº“åˆ†å¸ƒ (Top 10)")
            lines.append("")
            lines.append("| ä»“åº“ | ä»»åŠ¡æ•° |")
            lines.append("|------|--------|")
            for repo, count in sorted(swe_stats["repos"].items(), key=lambda x: -x[1])[:10]:
                lines.append(f"| `{repo}` | {count} |")
            lines.append("")

        # Issue types
        if swe_stats.get("issue_types"):
            lines.append("### é—®é¢˜ç±»å‹åˆ†å¸ƒ")
            lines.append("")
            lines.append("| ç±»å‹ | æ•°é‡ |")
            lines.append("|------|------|")
            for itype, count in sorted(swe_stats["issue_types"].items(), key=lambda x: -x[1]):
                lines.append(f"| `{itype}` | {count} |")
            lines.append("")

        # Issue categories
        if swe_stats.get("issue_categories"):
            lines.append("### æ‰€éœ€çŸ¥è¯†é¢†åŸŸ")
            lines.append("")
            lines.append("| é¢†åŸŸ | æ•°é‡ |")
            lines.append("|------|------|")
            for cat, count in sorted(swe_stats["issue_categories"].items(), key=lambda x: -x[1]):
                lines.append(f"| `{cat}` | {count} |")
            lines.append("")

        # Patch complexity
        if swe_stats.get("patch_lines"):
            avg_lines = sum(swe_stats["patch_lines"]) / len(swe_stats["patch_lines"])
            max_lines = max(swe_stats["patch_lines"])
            min_lines = min(swe_stats["patch_lines"])
            lines.append("### ä»£ç ä¿®æ”¹å¤æ‚åº¦")
            lines.append("")
            lines.append(f"- **å¹³å‡ä¿®æ”¹è¡Œæ•°**: {avg_lines:.1f} è¡Œ")
            lines.append(f"- **æœ€å¤§ä¿®æ”¹**: {max_lines} è¡Œ")
            lines.append(f"- **æœ€å°ä¿®æ”¹**: {min_lines} è¡Œ")
            lines.append("")

        # Problem statement examples
        if swe_stats.get("examples"):
            lines.append("### é—®é¢˜æè¿°ç¤ºä¾‹")
            lines.append("")
            for i, ex in enumerate(swe_stats["examples"][:2], 1):
                lines.append(
                    f"**ç¤ºä¾‹ {i}** (`{ex.get('repo', 'unknown')}` - {ex.get('language', 'unknown')})"
                )
                lines.append("")
                lines.append("**Problem Statement:**")
                lines.append("```")
                lines.append(ex.get("problem_statement", "")[:600])
                lines.append("```")
                lines.append("")
                if ex.get("requirements"):
                    lines.append("**Requirements:**")
                    lines.append("```")
                    lines.append(ex.get("requirements", "")[:400])
                    lines.append("```")
                    lines.append("")

        # SOP for SWE-bench dataset
        lines.append("### SWE-bench æ•°æ®ç”Ÿäº§ SOP")
        lines.append("")
        lines.append("```")
        lines.append("Phase 1: ä»“åº“ç­›é€‰")
        lines.append("â”œâ”€ æ­¥éª¤ 1.1: é€‰æ‹©æ´»è·ƒçš„å¼€æºä»“åº“ï¼ˆGPL ç­‰å¼º copyleft è®¸å¯ä¼˜å…ˆï¼‰")
        lines.append("â”œâ”€ æ­¥éª¤ 1.2: ç¡®ä¿æœ‰å®Œå–„çš„æµ‹è¯•å¥—ä»¶")
        lines.append("â””â”€ æ­¥éª¤ 1.3: ç­›é€‰æœ‰æ¸…æ™° issue/PR å†å²çš„ä»“åº“")
        lines.append("")
        lines.append("Phase 2: ä»»åŠ¡æŒ–æ˜")
        lines.append("â”œâ”€ æ­¥éª¤ 2.1: ä»å·²åˆå¹¶çš„ PR ä¸­æå– bug fix / feature")
        lines.append("â”œâ”€ æ­¥éª¤ 2.2: æå– base_commit (ä¿®å¤å‰) å’Œ patch (ä¿®å¤å†…å®¹)")
        lines.append("â”œâ”€ æ­¥éª¤ 2.3: è¯†åˆ« fail-to-pass æµ‹è¯•ï¼ˆä¿®å¤ååº”é€šè¿‡ï¼‰")
        lines.append("â””â”€ æ­¥éª¤ 2.4: è¯†åˆ« pass-to-pass æµ‹è¯•ï¼ˆç¡®ä¿æ— å›å½’ï¼‰")
        lines.append("")
        lines.append("Phase 3: ä»»åŠ¡å¢å¼º")
        lines.append("â”œâ”€ æ­¥éª¤ 3.1: æ’°å†™ problem_statementï¼ˆé—®é¢˜æè¿°ï¼‰")
        lines.append("â”œâ”€ æ­¥éª¤ 3.2: æ’°å†™ requirementsï¼ˆåŠŸèƒ½éœ€æ±‚ï¼‰")
        lines.append("â”œâ”€ æ­¥éª¤ 3.3: æ ‡æ³¨ interfaceï¼ˆæ¶‰åŠçš„ API/å‡½æ•°ï¼‰")
        lines.append("â””â”€ æ­¥éª¤ 3.4: åˆ†ç±» issue_categoriesï¼ˆæ‰€éœ€çŸ¥è¯†é¢†åŸŸï¼‰")
        lines.append("")
        lines.append("Phase 4: è´¨é‡éªŒè¯")
        lines.append("â”œâ”€ æ­¥éª¤ 4.1: éªŒè¯ patch èƒ½é€šè¿‡æ‰€æœ‰æµ‹è¯•")
        lines.append("â”œâ”€ æ­¥éª¤ 4.2: ç¡®ä¿ problem_statement ä¸æ³„éœ²è§£å†³æ–¹æ¡ˆ")
        lines.append("â””â”€ æ­¥éª¤ 4.3: éªŒè¯ä»»åŠ¡å¯ç”±äººç±»å·¥ç¨‹å¸ˆç‹¬ç«‹å®Œæˆ")
        lines.append("```")
        lines.append("")

        # Quality criteria
        lines.append("### æ•°æ®è´¨é‡æ ‡å‡†")
        lines.append("")
        lines.append("| ç»´åº¦ | è¦æ±‚ |")
        lines.append("|------|------|")
        lines.append("| **é—®é¢˜æè¿°** | æ¸…æ™°æè¿° bug ç°è±¡æˆ–åŠŸèƒ½éœ€æ±‚ï¼Œä¸æ³„éœ²è§£å†³æ–¹æ¡ˆ |")
        lines.append("| **æµ‹è¯•è¦†ç›–** | è‡³å°‘æœ‰ 1 ä¸ª fail-to-pass æµ‹è¯•éªŒè¯ä¿®å¤æ­£ç¡®æ€§ |")
        lines.append("| **æ— å›å½’** | pass-to-pass æµ‹è¯•ç¡®ä¿ä¸å¼•å…¥æ–° bug |")
        lines.append("| **å¯å¤ç°** | æä¾›å®Œæ•´çš„ç¯å¢ƒè®¾ç½®å‘½ä»¤ |")
        lines.append("| **åˆç†å¤æ‚åº¦** | ä¿®æ”¹è¡Œæ•°é€‚ä¸­ï¼Œä¸è¿‡äºç®€å•ä¹Ÿä¸è¿‡äºå¤æ‚ |")
        lines.append("")
        lines.append("---")
        lines.append("")

    # ==================== Section 3: System Prompt Templates ====================
    lines.append("## 3ï¸âƒ£ System Prompt æ¨¡æ¿åº“")
    lines.append("")
    lines.append("> ä»¥ä¸‹æ˜¯ä»æ•°æ®é›†ä¸­æå–çš„çœŸå® System Prompt ç¤ºä¾‹ï¼Œå¯ç›´æ¥å¤ç”¨æˆ–æ”¹ç¼–ã€‚")
    lines.append("")

    if system_prompts_by_domain:
        for domain, prompts in list(system_prompts_by_domain.items())[:5]:
            lines.append(
                f"### 3.{list(system_prompts_by_domain.keys()).index(domain) + 1} {domain}"
            )
            lines.append("")
            for i, p in enumerate(prompts[:2], 1):
                content = p["content"]
                # Truncate if too long
                if len(content) > 1500:
                    content = content[:1500] + "\n\n... (æˆªæ–­ï¼Œå®Œæ•´å†…å®¹è§ prompt_templates.json)"
                lines.append(f"**ç¤ºä¾‹ {i}:**")
                lines.append("")
                lines.append("```")
                lines.append(content)
                lines.append("```")
                lines.append("")
    else:
        lines.append("æœªæå–åˆ° System Prompt")
        lines.append("")

    lines.append("---")
    lines.append("")

    # ==================== Section 4: Rubric Writing Guide ====================
    lines.append("## 4ï¸âƒ£ è¯„åˆ†æ ‡å‡† (Rubric) ç¼–å†™è§„èŒƒ")
    lines.append("")

    if rubrics_result:
        lines.append("### 4.1 å¥å¼æ¨¡å¼")
        lines.append("")
        lines.append("ä»æ•°æ®é›†ä¸­å‘ç°çš„é«˜é¢‘å¥å¼æ¨¡å¼ï¼š")
        lines.append("")

        # Top verbs
        sorted_verbs = sorted(rubrics_result.verb_distribution.items(), key=lambda x: -x[1])[:8]
        lines.append("| æ ¸å¿ƒåŠ¨è¯ | é¢‘æ¬¡ | ç¤ºä¾‹å¥å¼ |")
        lines.append("|----------|------|----------|")
        verb_examples = {
            "include": "The response should include [å…·ä½“å†…å®¹]",
            "state": "The response should state [å…·ä½“äº‹å®]",
            "explain": "The response should explain [æ¦‚å¿µ/åŸå› ]",
            "provide": "The response should provide [ä¿¡æ¯/ç¤ºä¾‹]",
            "not": "The response should not [ç¦æ­¢è¡Œä¸º]",
            "identify": "The response should identify [ç›®æ ‡å¯¹è±¡]",
            "use": "The response should use [æŒ‡å®šæ–¹æ³•/æ ¼å¼]",
            "define": "The response should define [æœ¯è¯­/æ¦‚å¿µ]",
            "list": "The response should list [æ¡ç›®/æ­¥éª¤]",
            "describe": "The response should describe [æè¿°å¯¹è±¡]",
        }
        for verb, count in sorted_verbs:
            example = verb_examples.get(verb, f"... should {verb} ...")
            lines.append(f"| **{verb}** | {count} | `{example}` |")
        lines.append("")

        lines.append("### 4.2 è¯„åˆ†æ ‡å‡†ç»“æ„")
        lines.append("")
        lines.append("æ¨èé‡‡ç”¨ä»¥ä¸‹ç»“æ„ç¼–å†™è¯„åˆ†æ ‡å‡†ï¼š")
        lines.append("")
        lines.append("```")
        lines.append("[ä¸»è¯­] should [åŠ¨ä½œ] [ç›®æ ‡]. [æ¡ä»¶/ä¾‹å¤–]. Fail if [å¤±è´¥æ¡ä»¶].")
        lines.append("```")
        lines.append("")
        lines.append("**ç»“æ„è¯´æ˜ï¼š**")
        lines.append("")
        lines.append("| ç»„æˆéƒ¨åˆ† | è¯´æ˜ | ç¤ºä¾‹ |")
        lines.append("|----------|------|------|")
        lines.append("| ä¸»è¯­ | è¢«è¯„ä¼°å¯¹è±¡ | The response / The model / The answer |")
        lines.append("| åŠ¨ä½œ | æœŸæœ›è¡Œä¸º | should include / should explain / should not |")
        lines.append("| ç›®æ ‡ | å…·ä½“å†…å®¹ | the definition of X / at least 3 examples |")
        lines.append("| æ¡ä»¶ | é€‚ç”¨èŒƒå›´ | For example, ... / When X, ... |")
        lines.append("| å¤±è´¥æ¡ä»¶ | æ‰£åˆ†æ ‡å‡† | Fail if X is missing / Fail if incorrect |")
        lines.append("")

    # Real rubric examples
    if rubrics_examples:
        lines.append("### 4.3 å®Œæ•´ç¤ºä¾‹")
        lines.append("")
        lines.append("> ä»¥ä¸‹æ˜¯ä»æ•°æ®é›†ä¸­æå–çš„çœŸå®è¯„åˆ†æ ‡å‡†ç¤ºä¾‹ï¼š")
        lines.append("")

        for i, ex in enumerate(rubrics_examples[:3], 1):
            meta = ex.get("metadata", {})
            cat = meta.get("context_category", meta.get("category", "unknown"))
            sub = meta.get("sub_category", "")

            lines.append(f"**ç¤ºä¾‹ {i}** (`{cat}` / `{sub}`)")
            lines.append("")
            for j, r in enumerate(ex["rubrics"][:5], 1):
                lines.append(f"{j}. {r}")
            if len(ex["rubrics"]) > 5:
                lines.append(f"   ... (å…± {len(ex['rubrics'])} æ¡)")
            lines.append("")

    lines.append("---")
    lines.append("")

    # ==================== Section 5: Step-by-Step SOP ====================
    lines.append("## 5ï¸âƒ£ å¤åˆ» SOP (æ ‡å‡†æ“ä½œæµç¨‹)")
    lines.append("")
    lines.append("### Phase 1: å‡†å¤‡é˜¶æ®µ")
    lines.append("")
    lines.append("```")
    lines.append("æ­¥éª¤ 1.1: ç¡®å®šç›®æ ‡é¢†åŸŸå’Œåˆ†ç±»ä½“ç³»")
    lines.append("         â”œâ”€ å‚è€ƒä¸Šæ–¹ã€Œä»»åŠ¡åˆ†ç±»ä½“ç³»ã€")
    lines.append("         â””â”€ ç¡®å®šè¦è¦†ç›–çš„ context_category åˆ—è¡¨")
    lines.append("")
    lines.append("æ­¥éª¤ 1.2: æ”¶é›†åŸå§‹ä¸Šä¸‹æ–‡ææ–™")
    lines.append("         â”œâ”€ ä¸“ä¸šæ–‡æ¡£ã€æ‰‹å†Œã€è§„èŒƒ")
    lines.append("         â”œâ”€ ç¡®ä¿ææ–™ä¸åœ¨ LLM è®­ç»ƒæ•°æ®ä¸­")
    lines.append("         â””â”€ æ¯ä¸ªåˆ†ç±»å‡†å¤‡ 10-20 ä»½ææ–™")
    lines.append("")
    lines.append("æ­¥éª¤ 1.3: å‡†å¤‡ System Prompt æ¨¡æ¿")
    lines.append("         â”œâ”€ å‚è€ƒä¸Šæ–¹ã€ŒSystem Prompt æ¨¡æ¿åº“ã€")
    lines.append("         â””â”€ æŒ‰é¢†åŸŸå®šåˆ¶è§’è‰²è®¾å®š")
    lines.append("```")
    lines.append("")

    lines.append("### Phase 2: æ•°æ®ç”Ÿæˆé˜¶æ®µ")
    lines.append("")
    lines.append("```")
    lines.append("æ­¥éª¤ 2.1: ç¼–å†™ System Prompt")
    lines.append("         â”œâ”€ å®šä¹‰ AI è§’è‰²å’Œèƒ½åŠ›è¾¹ç•Œ")
    lines.append("         â”œâ”€ è®¾ç½®è¾“å‡ºæ ¼å¼çº¦æŸ")
    lines.append("         â””â”€ æ·»åŠ é¢†åŸŸç‰¹å®šæŒ‡ä»¤")
    lines.append("")
    lines.append("æ­¥éª¤ 2.2: æ„é€  User Query")
    lines.append("         â”œâ”€ åµŒå…¥ä¸Šä¸‹æ–‡ææ–™")
    lines.append("         â”œâ”€ è®¾è®¡éœ€è¦ç†è§£ä¸Šä¸‹æ–‡æ‰èƒ½å›ç­”çš„é—®é¢˜")
    lines.append("         â””â”€ é—®é¢˜åº”æœ‰æ˜ç¡®çš„è¯„ä¼°æ ‡å‡†")
    lines.append("")
    lines.append("æ­¥éª¤ 2.3: ç¼–å†™è¯„åˆ†æ ‡å‡† (Rubrics)")
    lines.append("         â”œâ”€ éµå¾ªä¸Šæ–¹ã€Œè¯„åˆ†æ ‡å‡†ç¼–å†™è§„èŒƒã€")
    lines.append("         â”œâ”€ æ¯ä¸ªä»»åŠ¡ 8-15 æ¡è¯„åˆ†æ ‡å‡†")
    lines.append("         â”œâ”€ è¦†ç›–ï¼šæ­£ç¡®æ€§ã€å®Œæ•´æ€§ã€æ ¼å¼ã€çº¦æŸ")
    lines.append("         â””â”€ ä½¿ç”¨ Fail if ... æ˜ç¡®å¤±è´¥æ¡ä»¶")
    lines.append("```")
    lines.append("")

    lines.append("### Phase 3: è´¨é‡æ§åˆ¶é˜¶æ®µ")
    lines.append("")
    lines.append("```")
    lines.append("æ­¥éª¤ 3.1: è‡ªæ£€")
    lines.append("         â”œâ”€ [ ] é—®é¢˜å¿…é¡»ä¾èµ–ä¸Šä¸‹æ–‡æ‰èƒ½å›ç­”")
    lines.append("         â”œâ”€ [ ] è¯„åˆ†æ ‡å‡†å¯é‡åŒ–ã€å¯æ‰§è¡Œ")
    lines.append("         â””â”€ [ ] æ•°æ®æ ¼å¼ç¬¦åˆ Schema è§„èŒƒ")
    lines.append("")
    lines.append("æ­¥éª¤ 3.2: äº¤å‰å®¡æ ¸")
    lines.append("         â”œâ”€ å¦ä¸€æ ‡æ³¨å‘˜ç‹¬ç«‹è¯„ä¼°")
    lines.append("         â”œâ”€ æ£€æŸ¥è¯„åˆ†æ ‡å‡†æ˜¯å¦é—æ¼")
    lines.append("         â””â”€ éªŒè¯æ ‡å‡†æ˜¯å¦å­˜åœ¨æ­§ä¹‰")
    lines.append("")
    lines.append("æ­¥éª¤ 3.3: æŠ½æ ·æµ‹è¯•")
    lines.append("         â”œâ”€ ç”¨ LLM ç”Ÿæˆå›ç­”")
    lines.append("         â”œâ”€ æŒ‰ Rubrics è¯„åˆ†")
    lines.append("         â””â”€ éªŒè¯è¯„åˆ†æ ‡å‡†çš„åŒºåˆ†åº¦")
    lines.append("```")
    lines.append("")

    lines.append("---")
    lines.append("")

    # ==================== Section 6: Complete Example ====================
    lines.append("## 6ï¸âƒ£ å®Œæ•´æ•°æ®ç¤ºä¾‹")
    lines.append("")

    if sample_items:
        item = sample_items[0]
        lines.append("```json")
        # Create a clean version for display
        display_item = {}
        for k, v in item.items():
            if k == "messages" and isinstance(v, list):
                display_messages = []
                for msg in v:
                    if isinstance(msg, dict):
                        content = msg.get("content", "")
                        if len(content) > 500:
                            msg = dict(msg)
                            msg["content"] = content[:500] + "... (truncated)"
                        display_messages.append(msg)
                display_item[k] = display_messages
            elif k == "rubrics" and isinstance(v, list):
                display_item[k] = v[:5] + ["... (truncated)"] if len(v) > 5 else v
            elif isinstance(v, str) and len(v) > 300:
                display_item[k] = v[:300] + "... (truncated)"
            else:
                display_item[k] = v
        lines.append(json.dumps(display_item, indent=2, ensure_ascii=False))
        lines.append("```")
    else:
        lines.append("æ— å¯ç”¨ç¤ºä¾‹")
    lines.append("")

    lines.append("---")
    lines.append("")

    # ==================== Section 7: Resource Estimation ====================
    lines.append("## 7ï¸âƒ£ èµ„æºä¼°ç®—")
    lines.append("")

    if allocation:
        lines.append("### 7.1 äººåŠ›é…ç½®å»ºè®®")
        lines.append("")
        lines.append("| è§’è‰² | äººæ•° | ä¸»è¦èŒè´£ |")
        lines.append("|------|------|----------|")
        lines.append("| é¢†åŸŸä¸“å®¶ | 2-4 | æä¾›ä¸Šä¸‹æ–‡ææ–™ï¼Œå®¡æ ¸ä¸“ä¸šæ€§ |")
        lines.append("| ä»»åŠ¡è®¾è®¡å¸ˆ | 1-2 | è®¾è®¡é—®é¢˜ï¼Œç¡®ä¿è¯„æµ‹æ•ˆåº¦ |")
        lines.append("| æ ‡æ³¨å‘˜ | 3-5 | ç¼–å†™è¯„åˆ†æ ‡å‡†ï¼Œæ ‡æ³¨æ•°æ® |")
        lines.append("| QA | 1-2 | è´¨é‡æŠ½æ£€ï¼Œä¸€è‡´æ€§æ ¡éªŒ |")
        lines.append("")

        lines.append("### 7.2 æˆæœ¬ä¼°ç®—")
        lines.append("")
        lines.append(f"- **äººå·¥æˆæœ¬**: ${allocation.total_human_cost:,.0f}")
        lines.append(f"- **API æˆæœ¬**: ${allocation.total_machine_cost:,.0f}")
        lines.append(f"- **æ€»è®¡**: ${allocation.total_cost:,.0f}")
        lines.append("")

    lines.append("---")
    lines.append("")

    # ==================== Section 8: Checklist ====================
    lines.append("## 8ï¸âƒ£ å‘å¸ƒå‰æ£€æŸ¥æ¸…å•")
    lines.append("")
    lines.append("### æ•°æ®è´¨é‡")
    lines.append("")
    lines.append("- [ ] æ‰€æœ‰å­—æ®µç¬¦åˆ Schema è§„èŒƒ")
    lines.append("- [ ] æ— ç©ºå€¼æˆ–å¼‚å¸¸å€¼")
    lines.append("- [ ] ä¸Šä¸‹æ–‡ææ–™ä¸åœ¨å…¬å¼€è®­ç»ƒé›†ä¸­")
    lines.append("- [ ] è¯„åˆ†æ ‡å‡†æ— æ­§ä¹‰ï¼Œå¯é‡åŒ–æ‰§è¡Œ")
    lines.append("")
    lines.append("### è¦†ç›–åº¦")
    lines.append("")
    lines.append("- [ ] å„åˆ†ç±»æ•°æ®é‡å‡è¡¡")
    lines.append("- [ ] éš¾åº¦åˆ†å¸ƒåˆç†")
    lines.append("- [ ] é¢†åŸŸè¦†ç›–å®Œæ•´")
    lines.append("")
    lines.append("### åˆè§„æ€§")
    lines.append("")
    lines.append("- [ ] æ— ç‰ˆæƒé—®é¢˜")
    lines.append("- [ ] æ— éšç§ä¿¡æ¯æ³„éœ²")
    lines.append("- [ ] æ ‡æ³¨è®¸å¯è¯æ˜ç¡®")
    lines.append("")
    lines.append("---")
    lines.append("")
    lines.append("> æŒ‡å—ç”± DataRecipe è‡ªåŠ¨ç”Ÿæˆ")

    return "\n".join(lines)
